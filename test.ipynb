{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so, 0x0002): tried: '/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (no such file), '/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscreenpro\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ngs\n",
      "File \u001b[0;32m~/Research/CRISPR-screenpro/ScreenPro2/screenpro/ngs.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbb\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compression\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfastq_to_dataframe\u001b[39m(fastq_file_path: \u001b[38;5;28mstr\u001b[39m,n_bp_from_5p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_bp_from_3p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023 WHERE TRUE Technologies.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Main biobear package.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasta_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastaReader\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastq_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastqReader\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvcf_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VCFReader, VCFIndexedReader\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/fasta_reader.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbiobear\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compression\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbiobear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ExonReader\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFastaReader\u001b[39;00m(Reader):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"FASTA file reader.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so, 0x0002): tried: '/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (no such file), '/opt/anaconda3/envs/mamba/envs/screenpro2/lib/python3.9/site-packages/biobear/biobear.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))"
     ]
    }
   ],
   "source": [
    "from screenpro import ngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load FASTQ file as a Polars DataFrame\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mngs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfastq_to_count_unique_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdemo/step1_process_fastq_files/example_crispri_v2_sample.fastq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/CRISPR-screenpro/ScreenPro2/screenpro/ngs.py:60\u001b[0m, in \u001b[0;36mfastq_to_count_unique_seq\u001b[0;34m(fastq_file_path, num_threads)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfastq_to_count_unique_seq\u001b[39m(fastq_file_path: \u001b[38;5;28mstr\u001b[39m, num_threads: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m---> 60\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfastq_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfastq_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount unique sequences\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Research/CRISPR-screenpro/ScreenPro2/screenpro/ngs.py:47\u001b[0m, in \u001b[0;36mfastq_to_dataframe\u001b[0;34m(fastq_file_path, num_threads, seq_only)\u001b[0m\n\u001b[1;32m     45\u001b[0m     df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame(records)\u001b[38;5;241m.\u001b[39mlazy()\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# df.columns = ['seq']\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mString\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame(records)\u001b[38;5;241m.\u001b[39mlazy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "ngs.fastq_to_count_unique_seq(\n",
    "    'demo/step1_process_fastq_files/example_crispri_v2_sample.fastq',\n",
    "    n_bp_from_5p=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.9'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LazyFrame in module polars.lazyframe.frame:\n",
      "\n",
      "class LazyFrame(builtins.object)\n",
      " |  LazyFrame(data: 'FrameInitTypes | None' = None, schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, orient: 'Orientation | None' = None, infer_schema_length: 'int | None' = 100, nan_to_null: 'bool' = False)\n",
      " |  \n",
      " |  Representation of a Lazy computation graph/query against a DataFrame.\n",
      " |  \n",
      " |  This allows for whole-query optimisation in addition to parallelism, and\n",
      " |  is the preferred (and highest-performance) mode of operation for polars.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : dict, Sequence, ndarray, Series, or pandas.DataFrame\n",
      " |      Two-dimensional data in various forms; dict input must contain Sequences,\n",
      " |      Generators, or a `range`. Sequence may contain Series or other Sequences.\n",
      " |  schema : Sequence of str, (str,DataType) pairs, or a {str:DataType,} dict\n",
      " |      The LazyFrame schema may be declared in several ways:\n",
      " |  \n",
      " |      * As a dict of {name:type} pairs; if type is None, it will be auto-inferred.\n",
      " |      * As a list of column names; in this case types are automatically inferred.\n",
      " |      * As a list of (name,type) pairs; this is equivalent to the dictionary form.\n",
      " |  \n",
      " |      If you supply a list of column names that does not match the names in the\n",
      " |      underlying data, the names given here will overwrite them. The number\n",
      " |      of names given in the schema should match the underlying data dimensions.\n",
      " |  schema_overrides : dict, default None\n",
      " |      Support type specification or override of one or more columns; note that\n",
      " |      any dtypes inferred from the schema param will be overridden.\n",
      " |  \n",
      " |      The number of entries in the schema should match the underlying data\n",
      " |      dimensions, unless a sequence of dictionaries is being passed, in which case\n",
      " |      a *partial* schema can be declared to prevent specific fields from being loaded.\n",
      " |  orient : {'col', 'row'}, default None\n",
      " |      Whether to interpret two-dimensional data as columns or as rows. If None,\n",
      " |      the orientation is inferred by matching the columns and data dimensions. If\n",
      " |      this does not yield conclusive results, column orientation is used.\n",
      " |  infer_schema_length : int or None\n",
      " |      The maximum number of rows to scan for schema inference.\n",
      " |      If set to `None`, the full data may be scanned *(this is slow)*.\n",
      " |      This parameter only applies if the input data is a sequence or generator of\n",
      " |      rows; other input is read as-is.\n",
      " |  nan_to_null : bool, default False\n",
      " |      If the data comes from one or more numpy arrays, can optionally convert input\n",
      " |      data np.nan values to null instead. This is a no-op for all other input data.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Initialising `LazyFrame(...)` directly is equivalent to `DataFrame(...).lazy()`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing a LazyFrame directly from a dictionary:\n",
      " |  \n",
      " |  >>> data = {\"a\": [1, 2], \"b\": [3, 4]}\n",
      " |  >>> lf = pl.LazyFrame(data)\n",
      " |  >>> lf.collect()\n",
      " |  shape: (2, 2)\n",
      " |  ┌─────┬─────┐\n",
      " |  │ a   ┆ b   │\n",
      " |  │ --- ┆ --- │\n",
      " |  │ i64 ┆ i64 │\n",
      " |  ╞═════╪═════╡\n",
      " |  │ 1   ┆ 3   │\n",
      " |  │ 2   ┆ 4   │\n",
      " |  └─────┴─────┘\n",
      " |  \n",
      " |  Notice that the dtypes are automatically inferred as polars Int64:\n",
      " |  \n",
      " |  >>> lf.dtypes\n",
      " |  [Int64, Int64]\n",
      " |  \n",
      " |  To specify a more detailed/specific frame schema you can supply the `schema`\n",
      " |  parameter with a dictionary of (name,dtype) pairs...\n",
      " |  \n",
      " |  >>> data = {\"col1\": [0, 2], \"col2\": [3, 7]}\n",
      " |  >>> lf2 = pl.LazyFrame(data, schema={\"col1\": pl.Float32, \"col2\": pl.Int64})\n",
      " |  >>> lf2.collect()\n",
      " |  shape: (2, 2)\n",
      " |  ┌──────┬──────┐\n",
      " |  │ col1 ┆ col2 │\n",
      " |  │ ---  ┆ ---  │\n",
      " |  │ f32  ┆ i64  │\n",
      " |  ╞══════╪══════╡\n",
      " |  │ 0.0  ┆ 3    │\n",
      " |  │ 2.0  ┆ 7    │\n",
      " |  └──────┴──────┘\n",
      " |  \n",
      " |  ...a sequence of (name,dtype) pairs...\n",
      " |  \n",
      " |  >>> data = {\"col1\": [1, 2], \"col2\": [3, 4]}\n",
      " |  >>> lf3 = pl.LazyFrame(data, schema=[(\"col1\", pl.Float32), (\"col2\", pl.Int64)])\n",
      " |  >>> lf3.collect()\n",
      " |  shape: (2, 2)\n",
      " |  ┌──────┬──────┐\n",
      " |  │ col1 ┆ col2 │\n",
      " |  │ ---  ┆ ---  │\n",
      " |  │ f32  ┆ i64  │\n",
      " |  ╞══════╪══════╡\n",
      " |  │ 1.0  ┆ 3    │\n",
      " |  │ 2.0  ┆ 4    │\n",
      " |  └──────┴──────┘\n",
      " |  \n",
      " |  ...or a list of typed Series.\n",
      " |  \n",
      " |  >>> data = [\n",
      " |  ...     pl.Series(\"col1\", [1, 2], dtype=pl.Float32),\n",
      " |  ...     pl.Series(\"col2\", [3, 4], dtype=pl.Int64),\n",
      " |  ... ]\n",
      " |  >>> lf4 = pl.LazyFrame(data)\n",
      " |  >>> lf4.collect()\n",
      " |  shape: (2, 2)\n",
      " |  ┌──────┬──────┐\n",
      " |  │ col1 ┆ col2 │\n",
      " |  │ ---  ┆ ---  │\n",
      " |  │ f32  ┆ i64  │\n",
      " |  ╞══════╪══════╡\n",
      " |  │ 1.0  ┆ 3    │\n",
      " |  │ 2.0  ┆ 4    │\n",
      " |  └──────┴──────┘\n",
      " |  \n",
      " |  Constructing a LazyFrame from a numpy ndarray, specifying column names:\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> data = np.array([(1, 2), (3, 4)], dtype=np.int64)\n",
      " |  >>> lf5 = pl.LazyFrame(data, schema=[\"a\", \"b\"], orient=\"col\")\n",
      " |  >>> lf5.collect()\n",
      " |  shape: (2, 2)\n",
      " |  ┌─────┬─────┐\n",
      " |  │ a   ┆ b   │\n",
      " |  │ --- ┆ --- │\n",
      " |  │ i64 ┆ i64 │\n",
      " |  ╞═════╪═════╡\n",
      " |  │ 1   ┆ 3   │\n",
      " |  │ 2   ┆ 4   │\n",
      " |  └─────┴─────┘\n",
      " |  \n",
      " |  Constructing a LazyFrame from a list of lists, row orientation inferred:\n",
      " |  \n",
      " |  >>> data = [[1, 2, 3], [4, 5, 6]]\n",
      " |  >>> lf6 = pl.LazyFrame(data, schema=[\"a\", \"b\", \"c\"])\n",
      " |  >>> lf6.collect()\n",
      " |  shape: (2, 3)\n",
      " |  ┌─────┬─────┬─────┐\n",
      " |  │ a   ┆ b   ┆ c   │\n",
      " |  │ --- ┆ --- ┆ --- │\n",
      " |  │ i64 ┆ i64 ┆ i64 │\n",
      " |  ╞═════╪═════╪═════╡\n",
      " |  │ 1   ┆ 2   ┆ 3   │\n",
      " |  │ 4   ┆ 5   ┆ 6   │\n",
      " |  └─────┴─────┴─────┘\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self) -> 'NoReturn'\n",
      " |  \n",
      " |  __contains__(self, key: 'str') -> 'bool'\n",
      " |  \n",
      " |  __copy__(self) -> 'Self'\n",
      " |  \n",
      " |  __deepcopy__(self, memo: 'None' = None) -> 'Self'\n",
      " |  \n",
      " |  __eq__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getitem__(self, item: 'int | range | slice') -> 'LazyFrame'\n",
      " |  \n",
      " |  __getstate__(self) -> 'bytes'\n",
      " |  \n",
      " |  __gt__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, data: 'FrameInitTypes | None' = None, schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, orient: 'Orientation | None' = None, infer_schema_length: 'int | None' = 100, nan_to_null: 'bool' = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __le__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other: 'Any') -> 'NoReturn'\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state: 'bytes') -> 'None'\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  approx_n_unique(self) -> 'Self'\n",
      " |      Approximate count of unique values.\n",
      " |      \n",
      " |      This is done using the HyperLogLog++ algorithm for cardinality estimation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.approx_n_unique().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ u32 ┆ u32 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 4   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  bottom_k(self, k: 'int', *, by: 'IntoExpr | Iterable[IntoExpr]', descending: 'bool | Sequence[bool]' = False, nulls_last: 'bool' = False, maintain_order: 'bool' = False) -> 'Self'\n",
      " |      Return the `k` smallest elements.\n",
      " |      \n",
      " |      If `descending=True` the largest elements will be given.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      k\n",
      " |          Number of rows to return.\n",
      " |      by\n",
      " |          Column(s) included in sort order. Accepts expression input.\n",
      " |          Strings are parsed as column names.\n",
      " |      descending\n",
      " |          Return the `k` largest. Bottom-k by multiple columns can be specified\n",
      " |          per column by passing a sequence of booleans.\n",
      " |      nulls_last\n",
      " |          Place null values last.\n",
      " |      maintain_order\n",
      " |          Whether the order should be maintained if elements are equal.\n",
      " |          Note that if `true` streaming is not possible and performance might be\n",
      " |          worse since this requires a stable search.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      top_k\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [2, 1, 1, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Get the rows which contain the 4 smallest values in column b.\n",
      " |      \n",
      " |      >>> lf.bottom_k(4, by=\"b\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ b   ┆ 1   │\n",
      " |      │ a   ┆ 1   │\n",
      " |      │ c   ┆ 1   │\n",
      " |      │ a   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Get the rows which contain the 4 smallest values when sorting on column a and b.\n",
      " |      \n",
      " |      >>> lf.bottom_k(4, by=[\"a\", \"b\"]).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ a   ┆ 1   │\n",
      " |      │ a   ┆ 2   │\n",
      " |      │ b   ┆ 1   │\n",
      " |      │ b   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  cache(self) -> 'Self'\n",
      " |      Cache the result once the execution of the physical plan hits this node.\n",
      " |  \n",
      " |  cast(self, dtypes: 'Mapping[ColumnNameOrSelector | PolarsDataType, PolarsDataType] | PolarsDataType', *, strict: 'bool' = True) -> 'Self'\n",
      " |      Cast LazyFrame column(s) to the specified dtype(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtypes\n",
      " |          Mapping of column names (or selector) to dtypes, or a single dtype\n",
      " |          to which all columns will be cast.\n",
      " |      strict\n",
      " |          Throw an error if a cast could not be done (for instance, due to an\n",
      " |          overflow).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from datetime import date\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6.0, 7.0, 8.0],\n",
      " |      ...         \"ham\": [date(2020, 1, 2), date(2021, 3, 4), date(2022, 5, 6)],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Cast specific frame columns to the specified dtypes:\n",
      " |      \n",
      " |      >>> lf.cast({\"foo\": pl.Float32, \"bar\": pl.UInt8}).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬────────────┐\n",
      " |      │ foo ┆ bar ┆ ham        │\n",
      " |      │ --- ┆ --- ┆ ---        │\n",
      " |      │ f32 ┆ u8  ┆ date       │\n",
      " |      ╞═════╪═════╪════════════╡\n",
      " |      │ 1.0 ┆ 6   ┆ 2020-01-02 │\n",
      " |      │ 2.0 ┆ 7   ┆ 2021-03-04 │\n",
      " |      │ 3.0 ┆ 8   ┆ 2022-05-06 │\n",
      " |      └─────┴─────┴────────────┘\n",
      " |      \n",
      " |      Cast all frame columns matching one dtype (or dtype group) to another dtype:\n",
      " |      \n",
      " |      >>> lf.cast({pl.Date: pl.Datetime}).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────────────────────┐\n",
      " |      │ foo ┆ bar ┆ ham                 │\n",
      " |      │ --- ┆ --- ┆ ---                 │\n",
      " |      │ i64 ┆ f64 ┆ datetime[μs]        │\n",
      " |      ╞═════╪═════╪═════════════════════╡\n",
      " |      │ 1   ┆ 6.0 ┆ 2020-01-02 00:00:00 │\n",
      " |      │ 2   ┆ 7.0 ┆ 2021-03-04 00:00:00 │\n",
      " |      │ 3   ┆ 8.0 ┆ 2022-05-06 00:00:00 │\n",
      " |      └─────┴─────┴─────────────────────┘\n",
      " |      \n",
      " |      Use selectors to define the columns being cast:\n",
      " |      \n",
      " |      >>> import polars.selectors as cs\n",
      " |      >>> lf.cast({cs.numeric(): pl.UInt32, cs.temporal(): pl.String}).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬────────────┐\n",
      " |      │ foo ┆ bar ┆ ham        │\n",
      " |      │ --- ┆ --- ┆ ---        │\n",
      " |      │ u32 ┆ u32 ┆ str        │\n",
      " |      ╞═════╪═════╪════════════╡\n",
      " |      │ 1   ┆ 6   ┆ 2020-01-02 │\n",
      " |      │ 2   ┆ 7   ┆ 2021-03-04 │\n",
      " |      │ 3   ┆ 8   ┆ 2022-05-06 │\n",
      " |      └─────┴─────┴────────────┘\n",
      " |      \n",
      " |      Cast all frame columns to the specified dtype:\n",
      " |      \n",
      " |      >>> lf.cast(pl.String).collect().to_dict(as_series=False)\n",
      " |      {'foo': ['1', '2', '3'],\n",
      " |       'bar': ['6.0', '7.0', '8.0'],\n",
      " |       'ham': ['2020-01-02', '2021-03-04', '2022-05-06']}\n",
      " |  \n",
      " |  clear(self, n: 'int' = 0) -> 'LazyFrame'\n",
      " |      Create an empty copy of the current LazyFrame, with zero to 'n' rows.\n",
      " |      \n",
      " |      Returns a copy with an identical schema but no data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Number of (empty) rows to return in the cleared frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clone : Cheap deepcopy/clone.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [None, 2, 3, 4],\n",
      " |      ...         \"b\": [0.5, None, 2.5, 13],\n",
      " |      ...         \"c\": [True, True, False, None],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.clear().fetch()\n",
      " |      shape: (0, 3)\n",
      " |      ┌─────┬─────┬──────┐\n",
      " |      │ a   ┆ b   ┆ c    │\n",
      " |      │ --- ┆ --- ┆ ---  │\n",
      " |      │ i64 ┆ f64 ┆ bool │\n",
      " |      ╞═════╪═════╪══════╡\n",
      " |      └─────┴─────┴──────┘\n",
      " |      \n",
      " |      >>> lf.clear(2).fetch()\n",
      " |      shape: (2, 3)\n",
      " |      ┌──────┬──────┬──────┐\n",
      " |      │ a    ┆ b    ┆ c    │\n",
      " |      │ ---  ┆ ---  ┆ ---  │\n",
      " |      │ i64  ┆ f64  ┆ bool │\n",
      " |      ╞══════╪══════╪══════╡\n",
      " |      │ null ┆ null ┆ null │\n",
      " |      │ null ┆ null ┆ null │\n",
      " |      └──────┴──────┴──────┘\n",
      " |  \n",
      " |  clone(self) -> 'Self'\n",
      " |      Create a copy of this LazyFrame.\n",
      " |      \n",
      " |      This is a cheap operation that does not copy data.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clear : Create an empty copy of the current LazyFrame, with identical\n",
      " |          schema but no data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [None, 2, 3, 4],\n",
      " |      ...         \"b\": [0.5, None, 2.5, 13],\n",
      " |      ...         \"c\": [True, True, False, None],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.clone()  # doctest: +ELLIPSIS\n",
      " |      <LazyFrame [3 cols, {\"a\": Int64 … \"c\": Boolean}] at ...>\n",
      " |  \n",
      " |  collect(self, *, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, no_optimization: 'bool' = False, streaming: 'bool' = False, background: 'bool' = False, _eager: 'bool' = False) -> 'DataFrame | InProcessQuery'\n",
      " |      Materialize this LazyFrame into a DataFrame.\n",
      " |      \n",
      " |      By default, all query optimizations are enabled. Individual optimizations may\n",
      " |      be disabled by setting the corresponding parameter to `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      streaming\n",
      " |          Process the query in batches to handle larger-than-memory data.\n",
      " |          If set to `False` (default), the entire query is processed in a single\n",
      " |          batch.\n",
      " |      \n",
      " |          .. warning::\n",
      " |              Streaming mode is considered **unstable**. It may be changed\n",
      " |              at any point without it being considered a breaking change.\n",
      " |      \n",
      " |          .. note::\n",
      " |              Use :func:`explain` to see if Polars can process the query in streaming\n",
      " |              mode.\n",
      " |      background\n",
      " |          Run the query in the background and get a handle to the query.\n",
      " |          This handle can be used to fetch the result or cancel the query.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fetch: Run the query on the first `n` rows only for debugging purposes.\n",
      " |      explain : Print the query plan that is evaluated with collect.\n",
      " |      profile : Collect the LazyFrame and time each node in the computation graph.\n",
      " |      polars.collect_all : Collect multiple LazyFrames at the same time.\n",
      " |      polars.Config.set_streaming_chunk_size : Set the size of streaming batches.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\").agg(pl.all().sum()).collect()  # doctest: +SKIP\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 4   ┆ 10  │\n",
      " |      │ b   ┆ 11  ┆ 10  │\n",
      " |      │ c   ┆ 6   ┆ 1   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Collect in streaming mode\n",
      " |      \n",
      " |      >>> lf.group_by(\"a\").agg(pl.all().sum()).collect(\n",
      " |      ...     streaming=True\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 4   ┆ 10  │\n",
      " |      │ b   ┆ 11  ┆ 10  │\n",
      " |      │ c   ┆ 6   ┆ 1   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  collect_async(self, *, gevent: 'bool' = False, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, no_optimization: 'bool' = False, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, streaming: 'bool' = False) -> 'Awaitable[DataFrame] | _GeventDataFrameResult[DataFrame]'\n",
      " |      Collect DataFrame asynchronously in thread pool.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          This functionality is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      Collects into a DataFrame (like :func:`collect`), but instead of returning\n",
      " |      DataFrame directly, they are scheduled to be collected inside thread pool,\n",
      " |      while this method returns almost instantly.\n",
      " |      \n",
      " |      May be useful if you use gevent or asyncio and want to release control to other\n",
      " |      greenlets/tasks while LazyFrames are being collected.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      gevent\n",
      " |          Return wrapper to `gevent.event.AsyncResult` instead of Awaitable\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      streaming\n",
      " |          Process the query in batches to handle larger-than-memory data.\n",
      " |          If set to `False` (default), the entire query is processed in a single\n",
      " |          batch.\n",
      " |      \n",
      " |          .. warning::\n",
      " |              Streaming mode is considered **unstable**. It may be changed\n",
      " |              at any point without it being considered a breaking change.\n",
      " |      \n",
      " |          .. note::\n",
      " |              Use :func:`explain` to see if Polars can process the query in streaming\n",
      " |              mode.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      If `gevent=False` (default) then returns awaitable.\n",
      " |      \n",
      " |      If `gevent=True` then returns wrapper that has\n",
      " |      `.get(block=True, timeout=None)` method.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      polars.collect_all : Collect multiple LazyFrames at the same time.\n",
      " |      polars.collect_all_async: Collect multiple LazyFrames at the same time lazily.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In case of error `set_exception` is used on\n",
      " |      `asyncio.Future`/`gevent.event.AsyncResult` and will be reraised by them.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import asyncio\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> async def main():\n",
      " |      ...     return await (\n",
      " |      ...         lf.group_by(\"a\", maintain_order=True)\n",
      " |      ...         .agg(pl.all().sum())\n",
      " |      ...         .collect_async()\n",
      " |      ...     )\n",
      " |      >>> asyncio.run(main())\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 4   ┆ 10  │\n",
      " |      │ b   ┆ 11  ┆ 10  │\n",
      " |      │ c   ┆ 6   ┆ 1   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  count(self) -> 'Self'\n",
      " |      Return the number of non-null elements for each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\"a\": [1, 2, 3, 4], \"b\": [1, 2, 1, None], \"c\": [None, None, None, None]}\n",
      " |      ... )\n",
      " |      >>> lf.count().collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ u32 ┆ u32 ┆ u32 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 4   ┆ 3   ┆ 0   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  describe(self, percentiles: 'Sequence[float] | float | None' = (0.25, 0.5, 0.75), *, interpolation: 'RollingInterpolationMethod' = 'nearest') -> 'DataFrame'\n",
      " |      Creates a summary of statistics for a LazyFrame, returning a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles\n",
      " |          One or more percentiles to include in the summary statistics.\n",
      " |          All values must be in the range `[0, 1]`.\n",
      " |      \n",
      " |      interpolation : {'nearest', 'higher', 'lower', 'midpoint', 'linear'}\n",
      " |          Interpolation method used when calculating percentiles.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The median is included by default as the 50% percentile.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      * This method does *not* maintain the laziness of the frame, and will `collect`\n",
      " |        the final result. This could potentially be an expensive operation.\n",
      " |      * We do not guarantee the output of `describe` to be stable. It will show\n",
      " |        statistics that we deem informative, and may be updated in the future.\n",
      " |        Using `describe` programmatically (versus interactive exploration) is\n",
      " |        not recommended for this reason.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from datetime import date, time\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"float\": [1.0, 2.8, 3.0],\n",
      " |      ...         \"int\": [40, 50, None],\n",
      " |      ...         \"bool\": [True, False, True],\n",
      " |      ...         \"str\": [\"zz\", \"xx\", \"yy\"],\n",
      " |      ...         \"date\": [date(2020, 1, 1), date(2021, 7, 5), date(2022, 12, 31)],\n",
      " |      ...         \"time\": [time(10, 20, 30), time(14, 45, 50), time(23, 15, 10)],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Show default frame statistics:\n",
      " |      \n",
      " |      >>> lf.describe()\n",
      " |      shape: (9, 7)\n",
      " |      ┌────────────┬──────────┬──────────┬──────────┬──────┬────────────┬──────────┐\n",
      " |      │ statistic  ┆ float    ┆ int      ┆ bool     ┆ str  ┆ date       ┆ time     │\n",
      " |      │ ---        ┆ ---      ┆ ---      ┆ ---      ┆ ---  ┆ ---        ┆ ---      │\n",
      " |      │ str        ┆ f64      ┆ f64      ┆ f64      ┆ str  ┆ str        ┆ str      │\n",
      " |      ╞════════════╪══════════╪══════════╪══════════╪══════╪════════════╪══════════╡\n",
      " |      │ count      ┆ 3.0      ┆ 2.0      ┆ 3.0      ┆ 3    ┆ 3          ┆ 3        │\n",
      " |      │ null_count ┆ 0.0      ┆ 1.0      ┆ 0.0      ┆ 0    ┆ 0          ┆ 0        │\n",
      " |      │ mean       ┆ 2.266667 ┆ 45.0     ┆ 0.666667 ┆ null ┆ 2021-07-02 ┆ 16:07:10 │\n",
      " |      │ std        ┆ 1.101514 ┆ 7.071068 ┆ null     ┆ null ┆ null       ┆ null     │\n",
      " |      │ min        ┆ 1.0      ┆ 40.0     ┆ 0.0      ┆ xx   ┆ 2020-01-01 ┆ 10:20:30 │\n",
      " |      │ 25%        ┆ 2.8      ┆ 40.0     ┆ null     ┆ null ┆ 2021-07-05 ┆ 14:45:50 │\n",
      " |      │ 50%        ┆ 2.8      ┆ 50.0     ┆ null     ┆ null ┆ 2021-07-05 ┆ 14:45:50 │\n",
      " |      │ 75%        ┆ 3.0      ┆ 50.0     ┆ null     ┆ null ┆ 2022-12-31 ┆ 23:15:10 │\n",
      " |      │ max        ┆ 3.0      ┆ 50.0     ┆ 1.0      ┆ zz   ┆ 2022-12-31 ┆ 23:15:10 │\n",
      " |      └────────────┴──────────┴──────────┴──────────┴──────┴────────────┴──────────┘\n",
      " |      \n",
      " |      Customize which percentiles are displayed, applying linear interpolation:\n",
      " |      \n",
      " |      >>> lf.describe(\n",
      " |      ...     percentiles=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
      " |      ...     interpolation=\"linear\",\n",
      " |      ... )\n",
      " |      shape: (11, 7)\n",
      " |      ┌────────────┬──────────┬──────────┬──────────┬──────┬────────────┬──────────┐\n",
      " |      │ statistic  ┆ float    ┆ int      ┆ bool     ┆ str  ┆ date       ┆ time     │\n",
      " |      │ ---        ┆ ---      ┆ ---      ┆ ---      ┆ ---  ┆ ---        ┆ ---      │\n",
      " |      │ str        ┆ f64      ┆ f64      ┆ f64      ┆ str  ┆ str        ┆ str      │\n",
      " |      ╞════════════╪══════════╪══════════╪══════════╪══════╪════════════╪══════════╡\n",
      " |      │ count      ┆ 3.0      ┆ 2.0      ┆ 3.0      ┆ 3    ┆ 3          ┆ 3        │\n",
      " |      │ null_count ┆ 0.0      ┆ 1.0      ┆ 0.0      ┆ 0    ┆ 0          ┆ 0        │\n",
      " |      │ mean       ┆ 2.266667 ┆ 45.0     ┆ 0.666667 ┆ null ┆ 2021-07-02 ┆ 16:07:10 │\n",
      " |      │ std        ┆ 1.101514 ┆ 7.071068 ┆ null     ┆ null ┆ null       ┆ null     │\n",
      " |      │ min        ┆ 1.0      ┆ 40.0     ┆ 0.0      ┆ xx   ┆ 2020-01-01 ┆ 10:20:30 │\n",
      " |      │ 10%        ┆ 1.36     ┆ 41.0     ┆ null     ┆ null ┆ 2020-04-20 ┆ 11:13:34 │\n",
      " |      │ 30%        ┆ 2.08     ┆ 43.0     ┆ null     ┆ null ┆ 2020-11-26 ┆ 12:59:42 │\n",
      " |      │ 50%        ┆ 2.8      ┆ 45.0     ┆ null     ┆ null ┆ 2021-07-05 ┆ 14:45:50 │\n",
      " |      │ 70%        ┆ 2.88     ┆ 47.0     ┆ null     ┆ null ┆ 2022-02-07 ┆ 18:09:34 │\n",
      " |      │ 90%        ┆ 2.96     ┆ 49.0     ┆ null     ┆ null ┆ 2022-09-13 ┆ 21:33:18 │\n",
      " |      │ max        ┆ 3.0      ┆ 50.0     ┆ 1.0      ┆ zz   ┆ 2022-12-31 ┆ 23:15:10 │\n",
      " |      └────────────┴──────────┴──────────┴──────────┴──────┴────────────┴──────────┘\n",
      " |  \n",
      " |  drop(self, *columns: 'ColumnNameOrSelector | Iterable[ColumnNameOrSelector]') -> 'Self'\n",
      " |      Remove columns from the DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *columns\n",
      " |          Names of the columns that should be removed from the dataframe.\n",
      " |          Accepts column selector input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Drop a single column by passing the name of that column.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6.0, 7.0, 8.0],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.drop(\"ham\").collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ foo ┆ bar │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ f64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 6.0 │\n",
      " |      │ 2   ┆ 7.0 │\n",
      " |      │ 3   ┆ 8.0 │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Drop multiple columns by passing a selector.\n",
      " |      \n",
      " |      >>> import polars.selectors as cs\n",
      " |      >>> lf.drop(cs.numeric()).collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌─────┐\n",
      " |      │ ham │\n",
      " |      │ --- │\n",
      " |      │ str │\n",
      " |      ╞═════╡\n",
      " |      │ a   │\n",
      " |      │ b   │\n",
      " |      │ c   │\n",
      " |      └─────┘\n",
      " |      \n",
      " |      Use positional arguments to drop multiple columns.\n",
      " |      \n",
      " |      >>> lf.drop(\"foo\", \"ham\").collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌─────┐\n",
      " |      │ bar │\n",
      " |      │ --- │\n",
      " |      │ f64 │\n",
      " |      ╞═════╡\n",
      " |      │ 6.0 │\n",
      " |      │ 7.0 │\n",
      " |      │ 8.0 │\n",
      " |      └─────┘\n",
      " |  \n",
      " |  drop_nulls(self, subset: 'ColumnNameOrSelector | Collection[ColumnNameOrSelector] | None' = None) -> 'Self'\n",
      " |      Drop all rows that contain null values.\n",
      " |      \n",
      " |      The original order of the remaining rows is preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset\n",
      " |          Column name(s) for which null values are considered.\n",
      " |          If set to `None` (default), use all columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6, None, 8],\n",
      " |      ...         \"ham\": [\"a\", \"b\", None],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      The default behavior of this method is to drop rows where any single\n",
      " |      value of the row is null.\n",
      " |      \n",
      " |      >>> lf.drop_nulls().collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      This behaviour can be constrained to consider only a subset of columns, as\n",
      " |      defined by name or with a selector. For example, dropping rows if there is\n",
      " |      a null in any of the integer columns:\n",
      " |      \n",
      " |      >>> import polars.selectors as cs\n",
      " |      >>> lf.drop_nulls(subset=cs.integer()).collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬──────┐\n",
      " |      │ foo ┆ bar ┆ ham  │\n",
      " |      │ --- ┆ --- ┆ ---  │\n",
      " |      │ i64 ┆ i64 ┆ str  │\n",
      " |      ╞═════╪═════╪══════╡\n",
      " |      │ 1   ┆ 6   ┆ a    │\n",
      " |      │ 3   ┆ 8   ┆ null │\n",
      " |      └─────┴─────┴──────┘\n",
      " |      \n",
      " |      This method drops a row if any single value of the row is null.\n",
      " |      \n",
      " |      Below are some example snippets that show how you could drop null\n",
      " |      values based on other conditions:\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [None, None, None, None],\n",
      " |      ...         \"b\": [1, 2, None, 1],\n",
      " |      ...         \"c\": [1, None, None, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.collect()\n",
      " |      shape: (4, 3)\n",
      " |      ┌──────┬──────┬──────┐\n",
      " |      │ a    ┆ b    ┆ c    │\n",
      " |      │ ---  ┆ ---  ┆ ---  │\n",
      " |      │ null ┆ i64  ┆ i64  │\n",
      " |      ╞══════╪══════╪══════╡\n",
      " |      │ null ┆ 1    ┆ 1    │\n",
      " |      │ null ┆ 2    ┆ null │\n",
      " |      │ null ┆ null ┆ null │\n",
      " |      │ null ┆ 1    ┆ 1    │\n",
      " |      └──────┴──────┴──────┘\n",
      " |      \n",
      " |      Drop a row only if all values are null:\n",
      " |      \n",
      " |      >>> lf.filter(~pl.all_horizontal(pl.all().is_null())).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬──────┐\n",
      " |      │ a    ┆ b   ┆ c    │\n",
      " |      │ ---  ┆ --- ┆ ---  │\n",
      " |      │ null ┆ i64 ┆ i64  │\n",
      " |      ╞══════╪═════╪══════╡\n",
      " |      │ null ┆ 1   ┆ 1    │\n",
      " |      │ null ┆ 2   ┆ null │\n",
      " |      │ null ┆ 1   ┆ 1    │\n",
      " |      └──────┴─────┴──────┘\n",
      " |  \n",
      " |  explain(self, *, optimized: 'bool' = True, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, streaming: 'bool' = False, tree_format: 'bool' = False) -> 'str'\n",
      " |      Create a string representation of the query plan.\n",
      " |      \n",
      " |      Different optimizations can be turned on or off.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      optimized\n",
      " |          Return an optimized query plan. Defaults to `True`.\n",
      " |          If this is set to `True` the subsequent\n",
      " |          optimization flags control which optimizations\n",
      " |          run.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      streaming\n",
      " |          Run parts of the query in a streaming fashion (this is in an alpha state)\n",
      " |      tree_format\n",
      " |          Format the output as a tree\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\", maintain_order=True).agg(pl.all().sum()).sort(\n",
      " |      ...     \"a\"\n",
      " |      ... ).explain()  # doctest: +SKIP\n",
      " |  \n",
      " |  explode(self, columns: 'str | Expr | Sequence[str | Expr]', *more_columns: 'str | Expr') -> 'Self'\n",
      " |      Explode the DataFrame to long format by exploding the given columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns\n",
      " |          Column names, expressions, or a selector defining them. The underlying\n",
      " |          columns being exploded must be of the `List` or `Array` data type.\n",
      " |      *more_columns\n",
      " |          Additional names of columns to explode, specified as positional arguments.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"letters\": [\"a\", \"a\", \"b\", \"c\"],\n",
      " |      ...         \"numbers\": [[1], [2, 3], [4, 5], [6, 7, 8]],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.explode(\"numbers\").collect()\n",
      " |      shape: (8, 2)\n",
      " |      ┌─────────┬─────────┐\n",
      " |      │ letters ┆ numbers │\n",
      " |      │ ---     ┆ ---     │\n",
      " |      │ str     ┆ i64     │\n",
      " |      ╞═════════╪═════════╡\n",
      " |      │ a       ┆ 1       │\n",
      " |      │ a       ┆ 2       │\n",
      " |      │ a       ┆ 3       │\n",
      " |      │ b       ┆ 4       │\n",
      " |      │ b       ┆ 5       │\n",
      " |      │ c       ┆ 6       │\n",
      " |      │ c       ┆ 7       │\n",
      " |      │ c       ┆ 8       │\n",
      " |      └─────────┴─────────┘\n",
      " |  \n",
      " |  fetch(self, n_rows: 'int' = 500, *, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, no_optimization: 'bool' = False, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, streaming: 'bool' = False) -> 'DataFrame'\n",
      " |      Collect a small number of rows for debugging purposes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n_rows\n",
      " |          Collect n_rows from the data sources.\n",
      " |      type_coercion\n",
      " |          Run type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Run predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Run projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      no_optimization\n",
      " |          Turn off optimizations.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      streaming\n",
      " |          Run parts of the query in a streaming fashion (this is in an alpha state)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is similar to a :func:`collect` operation, but it overwrites the number of\n",
      " |      rows read by *every* scan operation. Be aware that `fetch` does not guarantee\n",
      " |      the final number of rows in the DataFrame. Filters, join operations and fewer\n",
      " |      rows being available in the scanned data will all influence the final number\n",
      " |      of rows (joins are especially susceptible to this, and may return no data\n",
      " |      at all if `n_rows` is too small as the join keys may not be present).\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      This is strictly a utility function that can help to debug queries using a\n",
      " |      smaller number of rows, and should *not* be used in production code.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\", maintain_order=True).agg(pl.all().sum()).fetch(2)\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 1   ┆ 6   │\n",
      " |      │ b   ┆ 2   ┆ 5   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  fill_nan(self, value: 'int | float | Expr | None') -> 'Self'\n",
      " |      Fill floating point NaN values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value\n",
      " |          Value to fill the NaN values with.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Note that floating point NaN (Not a Number) are not missing values!\n",
      " |      To replace missing values, use :func:`fill_null` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1.5, 2, float(\"nan\"), 4],\n",
      " |      ...         \"b\": [0.5, 4, float(\"nan\"), 13],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.fill_nan(99).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌──────┬──────┐\n",
      " |      │ a    ┆ b    │\n",
      " |      │ ---  ┆ ---  │\n",
      " |      │ f64  ┆ f64  │\n",
      " |      ╞══════╪══════╡\n",
      " |      │ 1.5  ┆ 0.5  │\n",
      " |      │ 2.0  ┆ 4.0  │\n",
      " |      │ 99.0 ┆ 99.0 │\n",
      " |      │ 4.0  ┆ 13.0 │\n",
      " |      └──────┴──────┘\n",
      " |  \n",
      " |  fill_null(self, value: 'Any | None' = None, strategy: 'FillNullStrategy | None' = None, limit: 'int | None' = None, *, matches_supertype: 'bool' = True) -> 'Self'\n",
      " |      Fill null values using the specified value or strategy.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value\n",
      " |          Value used to fill null values.\n",
      " |      strategy : {None, 'forward', 'backward', 'min', 'max', 'mean', 'zero', 'one'}\n",
      " |          Strategy used to fill null values.\n",
      " |      limit\n",
      " |          Number of consecutive null values to fill when using the 'forward' or\n",
      " |          'backward' strategy.\n",
      " |      matches_supertype\n",
      " |          Fill all matching supertypes of the fill `value` literal.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, None, 4],\n",
      " |      ...         \"b\": [0.5, 4, None, 13],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.fill_null(99).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ a   ┆ b    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ i64 ┆ f64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 1   ┆ 0.5  │\n",
      " |      │ 2   ┆ 4.0  │\n",
      " |      │ 99  ┆ 99.0 │\n",
      " |      │ 4   ┆ 13.0 │\n",
      " |      └─────┴──────┘\n",
      " |      >>> lf.fill_null(strategy=\"forward\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ a   ┆ b    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ i64 ┆ f64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 1   ┆ 0.5  │\n",
      " |      │ 2   ┆ 4.0  │\n",
      " |      │ 2   ┆ 4.0  │\n",
      " |      │ 4   ┆ 13.0 │\n",
      " |      └─────┴──────┘\n",
      " |      \n",
      " |      >>> lf.fill_null(strategy=\"max\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ a   ┆ b    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ i64 ┆ f64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 1   ┆ 0.5  │\n",
      " |      │ 2   ┆ 4.0  │\n",
      " |      │ 4   ┆ 13.0 │\n",
      " |      │ 4   ┆ 13.0 │\n",
      " |      └─────┴──────┘\n",
      " |      \n",
      " |      >>> lf.fill_null(strategy=\"zero\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ a   ┆ b    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ i64 ┆ f64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 1   ┆ 0.5  │\n",
      " |      │ 2   ┆ 4.0  │\n",
      " |      │ 0   ┆ 0.0  │\n",
      " |      │ 4   ┆ 13.0 │\n",
      " |      └─────┴──────┘\n",
      " |  \n",
      " |  filter(self, *predicates: 'IntoExprColumn | Iterable[IntoExprColumn] | bool | list[bool] | np.ndarray[Any, Any]', **constraints: 'Any') -> 'Self'\n",
      " |      Filter the rows in the LazyFrame based on a predicate expression.\n",
      " |      \n",
      " |      The original order of the remaining rows is preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      predicates\n",
      " |          Expression that evaluates to a boolean Series.\n",
      " |      constraints\n",
      " |          Column filters; use `name = value` to filter columns by the supplied value.\n",
      " |          Each constraint will behave the same as `pl.col(name).eq(value)`, and\n",
      " |          will be implicitly joined with the other filter conditions using `&`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6, 7, 8],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Filter on one condition:\n",
      " |      \n",
      " |      >>> lf.filter(pl.col(\"foo\") > 1).collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 2   ┆ 7   ┆ b   │\n",
      " |      │ 3   ┆ 8   ┆ c   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Filter on multiple conditions:\n",
      " |      \n",
      " |      >>> lf.filter((pl.col(\"foo\") < 3) & (pl.col(\"ham\") == \"a\")).collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Provide multiple filters using `*args` syntax:\n",
      " |      \n",
      " |      >>> lf.filter(\n",
      " |      ...     pl.col(\"foo\") == 1,\n",
      " |      ...     pl.col(\"ham\") == \"a\",\n",
      " |      ... ).collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Provide multiple filters using `**kwargs` syntax:\n",
      " |      \n",
      " |      >>> lf.filter(foo=1, ham=\"a\").collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Filter on an OR condition:\n",
      " |      \n",
      " |      >>> lf.filter((pl.col(\"foo\") == 1) | (pl.col(\"ham\") == \"c\")).collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      │ 3   ┆ 8   ┆ c   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  first(self) -> 'Self'\n",
      " |      Get the first row of the DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 3, 5],\n",
      " |      ...         \"b\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.first().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  gather_every(self, n: 'int', offset: 'int' = 0) -> 'Self'\n",
      " |      Take every nth row in the LazyFrame and return as a new LazyFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Gather every *n*-th row.\n",
      " |      offset\n",
      " |          Starting index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [5, 6, 7, 8],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.gather_every(2).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 5   │\n",
      " |      │ 3   ┆ 7   │\n",
      " |      └─────┴─────┘\n",
      " |      >>> lf.gather_every(2, offset=1).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 2   ┆ 6   │\n",
      " |      │ 4   ┆ 8   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  group_by(self, *by: 'IntoExpr | Iterable[IntoExpr]', maintain_order: 'bool' = False, **named_by: 'IntoExpr') -> 'LazyGroupBy'\n",
      " |      Start a group by operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *by\n",
      " |          Column(s) to group by. Accepts expression input. Strings are parsed as\n",
      " |          column names.\n",
      " |      maintain_order\n",
      " |          Ensure that the order of the groups is consistent with the input data.\n",
      " |          This is slower than a default group by.\n",
      " |          Setting this to `True` blocks the possibility\n",
      " |          to run on the streaming engine.\n",
      " |      **named_by\n",
      " |          Additional columns to group by, specified as keyword arguments.\n",
      " |          The columns will be renamed to the keyword used.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Group by one column and call `agg` to compute the grouped sum of another\n",
      " |      column.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 1, 3, 3],\n",
      " |      ...         \"c\": [5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\").agg(pl.col(\"b\").sum()).collect()  # doctest: +IGNORE_RESULT\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ a   ┆ 2   │\n",
      " |      │ b   ┆ 5   │\n",
      " |      │ c   ┆ 3   │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Set `maintain_order=True` to ensure the order of the groups is consistent with\n",
      " |      the input.\n",
      " |      \n",
      " |      >>> lf.group_by(\"a\", maintain_order=True).agg(pl.col(\"c\")).collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬───────────┐\n",
      " |      │ a   ┆ c         │\n",
      " |      │ --- ┆ ---       │\n",
      " |      │ str ┆ list[i64] │\n",
      " |      ╞═════╪═══════════╡\n",
      " |      │ a   ┆ [5, 3]    │\n",
      " |      │ b   ┆ [4, 2]    │\n",
      " |      │ c   ┆ [1]       │\n",
      " |      └─────┴───────────┘\n",
      " |      \n",
      " |      Group by multiple columns by passing a list of column names.\n",
      " |      \n",
      " |      >>> lf.group_by([\"a\", \"b\"]).agg(pl.max(\"c\")).collect()  # doctest: +SKIP\n",
      " |      shape: (4, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 1   ┆ 5   │\n",
      " |      │ b   ┆ 2   ┆ 4   │\n",
      " |      │ b   ┆ 3   ┆ 2   │\n",
      " |      │ c   ┆ 3   ┆ 1   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      \n",
      " |      Or use positional arguments to group by multiple columns in the same way.\n",
      " |      Expressions are also accepted.\n",
      " |      \n",
      " |      >>> lf.group_by(\"a\", pl.col(\"b\") // 2).agg(\n",
      " |      ...     pl.col(\"c\").mean()\n",
      " |      ... ).collect()  # doctest: +SKIP\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ f64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ a   ┆ 0   ┆ 4.0 │\n",
      " |      │ b   ┆ 1   ┆ 3.0 │\n",
      " |      │ c   ┆ 1   ┆ 1.0 │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  group_by_dynamic(self, index_column: 'IntoExpr', *, every: 'str | timedelta', period: 'str | timedelta | None' = None, offset: 'str | timedelta | None' = None, truncate: 'bool | None' = None, include_boundaries: 'bool' = False, closed: 'ClosedInterval' = 'left', label: 'Label' = 'left', by: 'IntoExpr | Iterable[IntoExpr] | None' = None, start_by: 'StartBy' = 'window', check_sorted: 'bool' = True) -> 'LazyGroupBy'\n",
      " |      Group based on a time value (or index value of type Int32, Int64).\n",
      " |      \n",
      " |      Time windows are calculated and rows are assigned to windows. Different from a\n",
      " |      normal group by is that a row can be member of multiple groups.\n",
      " |      By default, the windows look like:\n",
      " |      \n",
      " |      - [start, start + period)\n",
      " |      - [start + every, start + every + period)\n",
      " |      - [start + 2*every, start + 2*every + period)\n",
      " |      - ...\n",
      " |      \n",
      " |      where `start` is determined by `start_by`, `offset`, and `every` (see parameter\n",
      " |      descriptions below).\n",
      " |      \n",
      " |      .. warning::\n",
      " |          The index column must be sorted in ascending order. If `by` is passed, then\n",
      " |          the index column must be sorted in ascending order within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index_column\n",
      " |          Column used to group based on the time window.\n",
      " |          Often of type Date/Datetime.\n",
      " |          This column must be sorted in ascending order (or, if `by` is specified,\n",
      " |          then it must be sorted in ascending order within each group).\n",
      " |      \n",
      " |          In case of a dynamic group by on indices, dtype needs to be one of\n",
      " |          {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\n",
      " |          performance matters use an Int64 column.\n",
      " |      every\n",
      " |          interval of the window\n",
      " |      period\n",
      " |          length of the window, if None it will equal 'every'\n",
      " |      offset\n",
      " |          offset of the window, only takes effect if `start_by` is `'window'`.\n",
      " |          Defaults to negative `every`.\n",
      " |      truncate\n",
      " |          truncate the time value to the window lower bound\n",
      " |      \n",
      " |          .. deprecated:: 0.19.4\n",
      " |              Use `label` instead.\n",
      " |      include_boundaries\n",
      " |          Add the lower and upper bound of the window to the \"_lower_boundary\" and\n",
      " |          \"_upper_boundary\" columns. This will impact performance because it's harder to\n",
      " |          parallelize\n",
      " |      closed : {'left', 'right', 'both', 'none'}\n",
      " |          Define which sides of the temporal interval are closed (inclusive).\n",
      " |      label : {'left', 'right', 'datapoint'}\n",
      " |          Define which label to use for the window:\n",
      " |      \n",
      " |          - 'left': lower boundary of the window\n",
      " |          - 'right': upper boundary of the window\n",
      " |          - 'datapoint': the first value of the index column in the given window.\n",
      " |            If you don't need the label to be at one of the boundaries, choose this\n",
      " |            option for maximum performance\n",
      " |      by\n",
      " |          Also group by this column/these columns\n",
      " |      start_by : {'window', 'datapoint', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'}\n",
      " |          The strategy to determine the start of the first window by.\n",
      " |      \n",
      " |          * 'window': Start by taking the earliest timestamp, truncating it with\n",
      " |            `every`, and then adding `offset`.\n",
      " |            Note that weekly windows start on Monday.\n",
      " |          * 'datapoint': Start from the first encountered data point.\n",
      " |          * a day of the week (only takes effect if `every` contains `'w'`):\n",
      " |      \n",
      " |            * 'monday': Start the window on the Monday before the first data point.\n",
      " |            * 'tuesday': Start the window on the Tuesday before the first data point.\n",
      " |            * ...\n",
      " |            * 'sunday': Start the window on the Sunday before the first data point.\n",
      " |      check_sorted\n",
      " |          When the `by` argument is given, polars can not check sortedness\n",
      " |          by the metadata and has to do a full scan on the index column to\n",
      " |          verify data is sorted. This is expensive. If you are sure the\n",
      " |          data within the by groups is sorted, you can set this to `False`.\n",
      " |          Doing so incorrectly will lead to incorrect output\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyGroupBy\n",
      " |          Object you can call `.agg` on to aggregate by groups, the result\n",
      " |          of which will be sorted by `index_column` (but note that if `by` columns are\n",
      " |          passed, it will only be sorted within each `by` group).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1) If you're coming from pandas, then\n",
      " |      \n",
      " |         .. code-block:: python\n",
      " |      \n",
      " |             # polars\n",
      " |             df.group_by_dynamic(\"ts\", every=\"1d\").agg(pl.col(\"value\").sum())\n",
      " |      \n",
      " |         is equivalent to\n",
      " |      \n",
      " |         .. code-block:: python\n",
      " |      \n",
      " |             # pandas\n",
      " |             df.set_index(\"ts\").resample(\"D\")[\"value\"].sum().reset_index()\n",
      " |      \n",
      " |         though note that, unlike pandas, polars doesn't add extra rows for empty\n",
      " |         windows. If you need `index_column` to be evenly spaced, then please combine\n",
      " |         with :func:`DataFrame.upsample`.\n",
      " |      \n",
      " |      2) The `every`, `period` and `offset` arguments are created with\n",
      " |         the following string language:\n",
      " |      \n",
      " |         - 1ns   (1 nanosecond)\n",
      " |         - 1us   (1 microsecond)\n",
      " |         - 1ms   (1 millisecond)\n",
      " |         - 1s    (1 second)\n",
      " |         - 1m    (1 minute)\n",
      " |         - 1h    (1 hour)\n",
      " |         - 1d    (1 calendar day)\n",
      " |         - 1w    (1 calendar week)\n",
      " |         - 1mo   (1 calendar month)\n",
      " |         - 1q    (1 calendar quarter)\n",
      " |         - 1y    (1 calendar year)\n",
      " |         - 1i    (1 index count)\n",
      " |      \n",
      " |         Or combine them:\n",
      " |         \"3d12h4m25s\" # 3 days, 12 hours, 4 minutes, and 25 seconds\n",
      " |      \n",
      " |         By \"calendar day\", we mean the corresponding time on the next day (which may\n",
      " |         not be 24 hours, due to daylight savings). Similarly for \"calendar week\",\n",
      " |         \"calendar month\", \"calendar quarter\", and \"calendar year\".\n",
      " |      \n",
      " |         In case of a group_by_dynamic on an integer column, the windows are defined by:\n",
      " |      \n",
      " |         - \"1i\"      # length 1\n",
      " |         - \"10i\"     # length 10\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from datetime import datetime\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"time\": pl.datetime_range(\n",
      " |      ...             start=datetime(2021, 12, 16),\n",
      " |      ...             end=datetime(2021, 12, 16, 3),\n",
      " |      ...             interval=\"30m\",\n",
      " |      ...             eager=True,\n",
      " |      ...         ),\n",
      " |      ...         \"n\": range(7),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.collect()\n",
      " |      shape: (7, 2)\n",
      " |      ┌─────────────────────┬─────┐\n",
      " |      │ time                ┆ n   │\n",
      " |      │ ---                 ┆ --- │\n",
      " |      │ datetime[μs]        ┆ i64 │\n",
      " |      ╞═════════════════════╪═════╡\n",
      " |      │ 2021-12-16 00:00:00 ┆ 0   │\n",
      " |      │ 2021-12-16 00:30:00 ┆ 1   │\n",
      " |      │ 2021-12-16 01:00:00 ┆ 2   │\n",
      " |      │ 2021-12-16 01:30:00 ┆ 3   │\n",
      " |      │ 2021-12-16 02:00:00 ┆ 4   │\n",
      " |      │ 2021-12-16 02:30:00 ┆ 5   │\n",
      " |      │ 2021-12-16 03:00:00 ┆ 6   │\n",
      " |      └─────────────────────┴─────┘\n",
      " |      \n",
      " |      Group by windows of 1 hour starting at 2021-12-16 00:00:00.\n",
      " |      \n",
      " |      >>> lf.group_by_dynamic(\"time\", every=\"1h\", closed=\"right\").agg(\n",
      " |      ...     pl.col(\"n\")\n",
      " |      ... ).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────────────────────┬───────────┐\n",
      " |      │ time                ┆ n         │\n",
      " |      │ ---                 ┆ ---       │\n",
      " |      │ datetime[μs]        ┆ list[i64] │\n",
      " |      ╞═════════════════════╪═══════════╡\n",
      " |      │ 2021-12-15 23:00:00 ┆ [0]       │\n",
      " |      │ 2021-12-16 00:00:00 ┆ [1, 2]    │\n",
      " |      │ 2021-12-16 01:00:00 ┆ [3, 4]    │\n",
      " |      │ 2021-12-16 02:00:00 ┆ [5, 6]    │\n",
      " |      └─────────────────────┴───────────┘\n",
      " |      \n",
      " |      The window boundaries can also be added to the aggregation result\n",
      " |      \n",
      " |      >>> lf.group_by_dynamic(\n",
      " |      ...     \"time\", every=\"1h\", include_boundaries=True, closed=\"right\"\n",
      " |      ... ).agg(pl.col(\"n\").mean()).collect()\n",
      " |      shape: (4, 4)\n",
      " |      ┌─────────────────────┬─────────────────────┬─────────────────────┬─────┐\n",
      " |      │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n   │\n",
      " |      │ ---                 ┆ ---                 ┆ ---                 ┆ --- │\n",
      " |      │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64 │\n",
      " |      ╞═════════════════════╪═════════════════════╪═════════════════════╪═════╡\n",
      " |      │ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ 0.0 │\n",
      " |      │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 1.5 │\n",
      " |      │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 3.5 │\n",
      " |      │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 5.5 │\n",
      " |      └─────────────────────┴─────────────────────┴─────────────────────┴─────┘\n",
      " |      \n",
      " |      When closed=\"left\", the window excludes the right end of interval:\n",
      " |      [lower_bound, upper_bound)\n",
      " |      \n",
      " |      >>> lf.group_by_dynamic(\"time\", every=\"1h\", closed=\"left\").agg(\n",
      " |      ...     pl.col(\"n\")\n",
      " |      ... ).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────────────────────┬───────────┐\n",
      " |      │ time                ┆ n         │\n",
      " |      │ ---                 ┆ ---       │\n",
      " |      │ datetime[μs]        ┆ list[i64] │\n",
      " |      ╞═════════════════════╪═══════════╡\n",
      " |      │ 2021-12-16 00:00:00 ┆ [0, 1]    │\n",
      " |      │ 2021-12-16 01:00:00 ┆ [2, 3]    │\n",
      " |      │ 2021-12-16 02:00:00 ┆ [4, 5]    │\n",
      " |      │ 2021-12-16 03:00:00 ┆ [6]       │\n",
      " |      └─────────────────────┴───────────┘\n",
      " |      \n",
      " |      When closed=\"both\" the time values at the window boundaries belong to 2 groups.\n",
      " |      \n",
      " |      >>> lf.group_by_dynamic(\"time\", every=\"1h\", closed=\"both\").agg(\n",
      " |      ...     pl.col(\"n\")\n",
      " |      ... ).collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────────────────────┬───────────┐\n",
      " |      │ time                ┆ n         │\n",
      " |      │ ---                 ┆ ---       │\n",
      " |      │ datetime[μs]        ┆ list[i64] │\n",
      " |      ╞═════════════════════╪═══════════╡\n",
      " |      │ 2021-12-15 23:00:00 ┆ [0]       │\n",
      " |      │ 2021-12-16 00:00:00 ┆ [0, 1, 2] │\n",
      " |      │ 2021-12-16 01:00:00 ┆ [2, 3, 4] │\n",
      " |      │ 2021-12-16 02:00:00 ┆ [4, 5, 6] │\n",
      " |      │ 2021-12-16 03:00:00 ┆ [6]       │\n",
      " |      └─────────────────────┴───────────┘\n",
      " |      \n",
      " |      Dynamic group bys can also be combined with grouping on normal keys\n",
      " |      \n",
      " |      >>> lf = lf.with_columns(groups=pl.Series([\"a\", \"a\", \"a\", \"b\", \"b\", \"a\", \"a\"]))\n",
      " |      >>> lf.collect()\n",
      " |      shape: (7, 3)\n",
      " |      ┌─────────────────────┬─────┬────────┐\n",
      " |      │ time                ┆ n   ┆ groups │\n",
      " |      │ ---                 ┆ --- ┆ ---    │\n",
      " |      │ datetime[μs]        ┆ i64 ┆ str    │\n",
      " |      ╞═════════════════════╪═════╪════════╡\n",
      " |      │ 2021-12-16 00:00:00 ┆ 0   ┆ a      │\n",
      " |      │ 2021-12-16 00:30:00 ┆ 1   ┆ a      │\n",
      " |      │ 2021-12-16 01:00:00 ┆ 2   ┆ a      │\n",
      " |      │ 2021-12-16 01:30:00 ┆ 3   ┆ b      │\n",
      " |      │ 2021-12-16 02:00:00 ┆ 4   ┆ b      │\n",
      " |      │ 2021-12-16 02:30:00 ┆ 5   ┆ a      │\n",
      " |      │ 2021-12-16 03:00:00 ┆ 6   ┆ a      │\n",
      " |      └─────────────────────┴─────┴────────┘\n",
      " |      >>> lf.group_by_dynamic(\n",
      " |      ...     \"time\",\n",
      " |      ...     every=\"1h\",\n",
      " |      ...     closed=\"both\",\n",
      " |      ...     by=\"groups\",\n",
      " |      ...     include_boundaries=True,\n",
      " |      ... ).agg(pl.col(\"n\")).collect()\n",
      " |      shape: (7, 5)\n",
      " |      ┌────────┬─────────────────────┬─────────────────────┬─────────────────────┬───────────┐\n",
      " |      │ groups ┆ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │\n",
      " |      │ ---    ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---       │\n",
      " |      │ str    ┆ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │\n",
      " |      ╞════════╪═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡\n",
      " |      │ a      ┆ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ [0]       │\n",
      " |      │ a      ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ [0, 1, 2] │\n",
      " |      │ a      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [2]       │\n",
      " |      │ a      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [5, 6]    │\n",
      " |      │ a      ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 04:00:00 ┆ 2021-12-16 03:00:00 ┆ [6]       │\n",
      " |      │ b      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [3, 4]    │\n",
      " |      │ b      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [4]       │\n",
      " |      └────────┴─────────────────────┴─────────────────────┴─────────────────────┴───────────┘\n",
      " |      \n",
      " |      Dynamic group by on an index column\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"idx\": pl.int_range(0, 6, eager=True),\n",
      " |      ...         \"A\": [\"A\", \"A\", \"B\", \"B\", \"B\", \"C\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by_dynamic(\n",
      " |      ...     \"idx\",\n",
      " |      ...     every=\"2i\",\n",
      " |      ...     period=\"3i\",\n",
      " |      ...     include_boundaries=True,\n",
      " |      ...     closed=\"right\",\n",
      " |      ... ).agg(pl.col(\"A\").alias(\"A_agg_list\")).collect()\n",
      " |      shape: (4, 4)\n",
      " |      ┌─────────────────┬─────────────────┬─────┬─────────────────┐\n",
      " |      │ _lower_boundary ┆ _upper_boundary ┆ idx ┆ A_agg_list      │\n",
      " |      │ ---             ┆ ---             ┆ --- ┆ ---             │\n",
      " |      │ i64             ┆ i64             ┆ i64 ┆ list[str]       │\n",
      " |      ╞═════════════════╪═════════════════╪═════╪═════════════════╡\n",
      " |      │ -2              ┆ 1               ┆ -2  ┆ [\"A\", \"A\"]      │\n",
      " |      │ 0               ┆ 3               ┆ 0   ┆ [\"A\", \"B\", \"B\"] │\n",
      " |      │ 2               ┆ 5               ┆ 2   ┆ [\"B\", \"B\", \"C\"] │\n",
      " |      │ 4               ┆ 7               ┆ 4   ┆ [\"C\"]           │\n",
      " |      └─────────────────┴─────────────────┴─────┴─────────────────┘\n",
      " |  \n",
      " |  group_by_rolling(self, index_column: 'IntoExpr', *, period: 'str | timedelta', offset: 'str | timedelta | None' = None, closed: 'ClosedInterval' = 'right', by: 'IntoExpr | Iterable[IntoExpr] | None' = None, check_sorted: 'bool' = True) -> 'LazyGroupBy'\n",
      " |      Create rolling groups based on a time, Int32, or Int64 column.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.9\n",
      " |          This method has been renamed to :func:`LazyFrame.rolling`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index_column\n",
      " |          Column used to group based on the time window.\n",
      " |          Often of type Date/Datetime.\n",
      " |          This column must be sorted in ascending order (or, if `by` is specified,\n",
      " |          then it must be sorted in ascending order within each group).\n",
      " |      \n",
      " |          In case of a rolling group by on indices, dtype needs to be one of\n",
      " |          {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\n",
      " |          performance matters use an Int64 column.\n",
      " |      period\n",
      " |          length of the window - must be non-negative\n",
      " |      offset\n",
      " |          offset of the window. Default is -period\n",
      " |      closed : {'right', 'left', 'both', 'none'}\n",
      " |          Define which sides of the temporal interval are closed (inclusive).\n",
      " |      by\n",
      " |          Also group by this column/these columns\n",
      " |      check_sorted\n",
      " |          When the `by` argument is given, polars can not check sortedness\n",
      " |          by the metadata and has to do a full scan on the index column to\n",
      " |          verify data is sorted. This is expensive. If you are sure the\n",
      " |          data within the by groups is sorted, you can set this to `False`.\n",
      " |          Doing so incorrectly will lead to incorrect output\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyGroupBy\n",
      " |          Object you can call `.agg` on to aggregate by groups, the result\n",
      " |          of which will be sorted by `index_column` (but note that if `by` columns are\n",
      " |          passed, it will only be sorted within each `by` group).\n",
      " |  \n",
      " |  groupby(self, by: 'IntoExpr | Iterable[IntoExpr]', *more_by: 'IntoExpr', maintain_order: 'bool' = False) -> 'LazyGroupBy'\n",
      " |      Start a group by operation.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.0\n",
      " |          This method has been renamed to :func:`LazyFrame.group_by`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by\n",
      " |          Column(s) to group by. Accepts expression input. Strings are parsed as\n",
      " |          column names.\n",
      " |      *more_by\n",
      " |          Additional columns to group by, specified as positional arguments.\n",
      " |      maintain_order\n",
      " |          Ensure that the order of the groups is consistent with the input data.\n",
      " |          This is slower than a default group by.\n",
      " |          Settings this to `True` blocks the possibility\n",
      " |          to run on the streaming engine.\n",
      " |  \n",
      " |  groupby_dynamic(self, index_column: 'IntoExpr', *, every: 'str | timedelta', period: 'str | timedelta | None' = None, offset: 'str | timedelta | None' = None, truncate: 'bool' = True, include_boundaries: 'bool' = False, closed: 'ClosedInterval' = 'left', by: 'IntoExpr | Iterable[IntoExpr] | None' = None, start_by: 'StartBy' = 'window', check_sorted: 'bool' = True) -> 'LazyGroupBy'\n",
      " |      Group based on a time value (or index value of type Int32, Int64).\n",
      " |      \n",
      " |      .. deprecated:: 0.19.0\n",
      " |          This method has been renamed to :func:`LazyFrame.group_by_dynamic`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index_column\n",
      " |          Column used to group based on the time window.\n",
      " |          Often of type Date/Datetime.\n",
      " |          This column must be sorted in ascending order (or, if `by` is specified,\n",
      " |          then it must be sorted in ascending order within each group).\n",
      " |      \n",
      " |          In case of a dynamic group by on indices, dtype needs to be one of\n",
      " |          {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\n",
      " |          performance matters use an Int64 column.\n",
      " |      every\n",
      " |          interval of the window\n",
      " |      period\n",
      " |          length of the window, if None it will equal 'every'\n",
      " |      offset\n",
      " |          offset of the window, only takes effect if `start_by` is `'window'`.\n",
      " |          Defaults to negative `every`.\n",
      " |      truncate\n",
      " |          truncate the time value to the window lower bound\n",
      " |      include_boundaries\n",
      " |          Add the lower and upper bound of the window to the \"_lower_bound\" and\n",
      " |          \"_upper_bound\" columns. This will impact performance because it's harder to\n",
      " |          parallelize\n",
      " |      closed : {'right', 'left', 'both', 'none'}\n",
      " |          Define which sides of the temporal interval are closed (inclusive).\n",
      " |      by\n",
      " |          Also group by this column/these columns\n",
      " |      start_by : {'window', 'datapoint', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'}\n",
      " |          The strategy to determine the start of the first window by.\n",
      " |      \n",
      " |          * 'window': Start by taking the earliest timestamp, truncating it with\n",
      " |            `every`, and then adding `offset`.\n",
      " |            Note that weekly windows start on Monday.\n",
      " |          * 'datapoint': Start from the first encountered data point.\n",
      " |          * a day of the week (only takes effect if `every` contains `'w'`):\n",
      " |      \n",
      " |            * 'monday': Start the window on the Monday before the first data point.\n",
      " |            * 'tuesday': Start the window on the Tuesday before the first data point.\n",
      " |            * ...\n",
      " |            * 'sunday': Start the window on the Sunday before the first data point.\n",
      " |      check_sorted\n",
      " |          When the `by` argument is given, polars can not check sortedness\n",
      " |          by the metadata and has to do a full scan on the index column to\n",
      " |          verify data is sorted. This is expensive. If you are sure the\n",
      " |          data within the by groups is sorted, you can set this to `False`.\n",
      " |          Doing so incorrectly will lead to incorrect output\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyGroupBy\n",
      " |          Object you can call `.agg` on to aggregate by groups, the result\n",
      " |          of which will be sorted by `index_column` (but note that if `by` columns are\n",
      " |          passed, it will only be sorted within each `by` group).\n",
      " |  \n",
      " |  groupby_rolling(self, index_column: 'IntoExpr', *, period: 'str | timedelta', offset: 'str | timedelta | None' = None, closed: 'ClosedInterval' = 'right', by: 'IntoExpr | Iterable[IntoExpr] | None' = None, check_sorted: 'bool' = True) -> 'LazyGroupBy'\n",
      " |      Create rolling groups based on a time, Int32, or Int64 column.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.0\n",
      " |          This method has been renamed to :func:`LazyFrame.rolling`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index_column\n",
      " |          Column used to group based on the time window.\n",
      " |          Often of type Date/Datetime.\n",
      " |          This column must be sorted in ascending order (or, if `by` is specified,\n",
      " |          then it must be sorted in ascending order within each group).\n",
      " |      \n",
      " |          In case of a rolling group by on indices, dtype needs to be one of\n",
      " |          {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\n",
      " |          performance matters use an Int64 column.\n",
      " |      period\n",
      " |          length of the window - must be non-negative\n",
      " |      offset\n",
      " |          offset of the window. Default is -period\n",
      " |      closed : {'right', 'left', 'both', 'none'}\n",
      " |          Define which sides of the temporal interval are closed (inclusive).\n",
      " |      by\n",
      " |          Also group by this column/these columns\n",
      " |      check_sorted\n",
      " |          When the `by` argument is given, polars can not check sortedness\n",
      " |          by the metadata and has to do a full scan on the index column to\n",
      " |          verify data is sorted. This is expensive. If you are sure the\n",
      " |          data within the by groups is sorted, you can set this to `False`.\n",
      " |          Doing so incorrectly will lead to incorrect output\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyGroupBy\n",
      " |          Object you can call `.agg` on to aggregate by groups, the result\n",
      " |          of which will be sorted by `index_column` (but note that if `by` columns are\n",
      " |          passed, it will only be sorted within each `by` group).\n",
      " |  \n",
      " |  head(self, n: 'int' = 5) -> 'Self'\n",
      " |      Get the first `n` rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Number of rows to return.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Consider using the :func:`fetch` operation if you only want to test your\n",
      " |      query. The :func:`fetch` operation will load the first `n` rows at the scan\n",
      " |      level, whereas the :func:`head`/:func:`limit` are applied at the end.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"b\": [7, 8, 9, 10, 11, 12],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.head().collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 7   │\n",
      " |      │ 2   ┆ 8   │\n",
      " |      │ 3   ┆ 9   │\n",
      " |      │ 4   ┆ 10  │\n",
      " |      │ 5   ┆ 11  │\n",
      " |      └─────┴─────┘\n",
      " |      >>> lf.head(2).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 7   │\n",
      " |      │ 2   ┆ 8   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  inspect(self, fmt: 'str' = '{}') -> 'Self'\n",
      " |      Inspect a node in the computation graph.\n",
      " |      \n",
      " |      Print the value that this node in the computation graph evaluates to and pass on\n",
      " |      the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame({\"foo\": [1, 1, -2, 3]})\n",
      " |      >>> (\n",
      " |      ...     lf.with_columns(pl.col(\"foo\").cum_sum().alias(\"bar\"))\n",
      " |      ...     .inspect()  # print the node before the filter\n",
      " |      ...     .filter(pl.col(\"bar\") == pl.col(\"foo\"))\n",
      " |      ... )  # doctest: +ELLIPSIS\n",
      " |      <LazyFrame [2 cols, {\"foo\": Int64, \"bar\": Int64}] at ...>\n",
      " |  \n",
      " |  interpolate(self) -> 'Self'\n",
      " |      Interpolate intermediate values. The interpolation method is linear.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, None, 9, 10],\n",
      " |      ...         \"bar\": [6, 7, 9, None],\n",
      " |      ...         \"baz\": [1, None, None, 9],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.interpolate().collect()\n",
      " |      shape: (4, 3)\n",
      " |      ┌──────┬──────┬──────────┐\n",
      " |      │ foo  ┆ bar  ┆ baz      │\n",
      " |      │ ---  ┆ ---  ┆ ---      │\n",
      " |      │ f64  ┆ f64  ┆ f64      │\n",
      " |      ╞══════╪══════╪══════════╡\n",
      " |      │ 1.0  ┆ 6.0  ┆ 1.0      │\n",
      " |      │ 5.0  ┆ 7.0  ┆ 3.666667 │\n",
      " |      │ 9.0  ┆ 9.0  ┆ 6.333333 │\n",
      " |      │ 10.0 ┆ null ┆ 9.0      │\n",
      " |      └──────┴──────┴──────────┘\n",
      " |  \n",
      " |  join(self, other: 'LazyFrame', on: 'str | Expr | Sequence[str | Expr] | None' = None, how: 'JoinStrategy' = 'inner', *, left_on: 'str | Expr | Sequence[str | Expr] | None' = None, right_on: 'str | Expr | Sequence[str | Expr] | None' = None, suffix: 'str' = '_right', validate: 'JoinValidation' = 'm:m', join_nulls: 'bool' = False, allow_parallel: 'bool' = True, force_parallel: 'bool' = False) -> 'Self'\n",
      " |      Add a join operation to the Logical Plan.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other\n",
      " |          Lazy DataFrame to join with.\n",
      " |      on\n",
      " |          Join column of both DataFrames. If set, `left_on` and `right_on` should be\n",
      " |          None.\n",
      " |      how : {'inner', 'left', 'outer', 'semi', 'anti', 'cross', 'outer_coalesce'}\n",
      " |          Join strategy.\n",
      " |      \n",
      " |          * *inner*\n",
      " |              Returns rows that have matching values in both tables\n",
      " |          * *left*\n",
      " |              Returns all rows from the left table, and the matched rows from the\n",
      " |              right table\n",
      " |          * *outer*\n",
      " |               Returns all rows when there is a match in either left or right table\n",
      " |          * *outer_coalesce*\n",
      " |               Same as 'outer', but coalesces the key columns\n",
      " |          * *cross*\n",
      " |               Returns the cartisian product of rows from both tables\n",
      " |          * *semi*\n",
      " |               Filter rows that have a match in the right table.\n",
      " |          * *anti*\n",
      " |               Filter rows that not have a match in the right table.\n",
      " |      \n",
      " |          .. note::\n",
      " |              A left join preserves the row order of the left DataFrame.\n",
      " |      left_on\n",
      " |          Join column of the left DataFrame.\n",
      " |      right_on\n",
      " |          Join column of the right DataFrame.\n",
      " |      suffix\n",
      " |          Suffix to append to columns with a duplicate name.\n",
      " |      validate: {'m:m', 'm:1', '1:m', '1:1'}\n",
      " |          Checks if join is of specified type.\n",
      " |      \n",
      " |              * *many_to_many*\n",
      " |                  “m:m”: default, does not result in checks\n",
      " |              * *one_to_one*\n",
      " |                  “1:1”: check if join keys are unique in both left and right datasets\n",
      " |              * *one_to_many*\n",
      " |                  “1:m”: check if join keys are unique in left dataset\n",
      " |              * *many_to_one*\n",
      " |                  “m:1”: check if join keys are unique in right dataset\n",
      " |      \n",
      " |          .. note::\n",
      " |      \n",
      " |              - This is currently not supported the streaming engine.\n",
      " |              - This is only supported when joined by single columns.\n",
      " |      join_nulls\n",
      " |          Join on null values. By default null values will never produce matches.\n",
      " |      allow_parallel\n",
      " |          Allow the physical plan to optionally evaluate the computation of both\n",
      " |          DataFrames up to the join in parallel.\n",
      " |      force_parallel\n",
      " |          Force the physical plan to evaluate the computation of both DataFrames up to\n",
      " |          the join in parallel.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      join_asof\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6.0, 7.0, 8.0],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> other_lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"apple\": [\"x\", \"y\", \"z\"],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"d\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.join(other_lf, on=\"ham\").collect()\n",
      " |      shape: (2, 4)\n",
      " |      ┌─────┬─────┬─────┬───────┐\n",
      " |      │ foo ┆ bar ┆ ham ┆ apple │\n",
      " |      │ --- ┆ --- ┆ --- ┆ ---   │\n",
      " |      │ i64 ┆ f64 ┆ str ┆ str   │\n",
      " |      ╞═════╪═════╪═════╪═══════╡\n",
      " |      │ 1   ┆ 6.0 ┆ a   ┆ x     │\n",
      " |      │ 2   ┆ 7.0 ┆ b   ┆ y     │\n",
      " |      └─────┴─────┴─────┴───────┘\n",
      " |      >>> lf.join(other_lf, on=\"ham\", how=\"outer\").collect()\n",
      " |      shape: (4, 5)\n",
      " |      ┌──────┬──────┬──────┬───────┬───────────┐\n",
      " |      │ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_right │\n",
      " |      │ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---       │\n",
      " |      │ i64  ┆ f64  ┆ str  ┆ str   ┆ str       │\n",
      " |      ╞══════╪══════╪══════╪═══════╪═══════════╡\n",
      " |      │ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a         │\n",
      " |      │ 2    ┆ 7.0  ┆ b    ┆ y     ┆ b         │\n",
      " |      │ null ┆ null ┆ null ┆ z     ┆ d         │\n",
      " |      │ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null      │\n",
      " |      └──────┴──────┴──────┴───────┴───────────┘\n",
      " |      >>> lf.join(other_lf, on=\"ham\", how=\"left\").collect()\n",
      " |      shape: (3, 4)\n",
      " |      ┌─────┬─────┬─────┬───────┐\n",
      " |      │ foo ┆ bar ┆ ham ┆ apple │\n",
      " |      │ --- ┆ --- ┆ --- ┆ ---   │\n",
      " |      │ i64 ┆ f64 ┆ str ┆ str   │\n",
      " |      ╞═════╪═════╪═════╪═══════╡\n",
      " |      │ 1   ┆ 6.0 ┆ a   ┆ x     │\n",
      " |      │ 2   ┆ 7.0 ┆ b   ┆ y     │\n",
      " |      │ 3   ┆ 8.0 ┆ c   ┆ null  │\n",
      " |      └─────┴─────┴─────┴───────┘\n",
      " |      >>> lf.join(other_lf, on=\"ham\", how=\"semi\").collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ f64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6.0 ┆ a   │\n",
      " |      │ 2   ┆ 7.0 ┆ b   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      >>> lf.join(other_lf, on=\"ham\", how=\"anti\").collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ f64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 3   ┆ 8.0 ┆ c   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  join_asof(self, other: 'LazyFrame', *, left_on: 'str | None | Expr' = None, right_on: 'str | None | Expr' = None, on: 'str | None | Expr' = None, by_left: 'str | Sequence[str] | None' = None, by_right: 'str | Sequence[str] | None' = None, by: 'str | Sequence[str] | None' = None, strategy: 'AsofJoinStrategy' = 'backward', suffix: 'str' = '_right', tolerance: 'str | int | float | timedelta | None' = None, allow_parallel: 'bool' = True, force_parallel: 'bool' = False) -> 'Self'\n",
      " |      Perform an asof join.\n",
      " |      \n",
      " |      This is similar to a left-join except that we match on nearest key rather than\n",
      " |      equal keys.\n",
      " |      \n",
      " |      Both DataFrames must be sorted by the join_asof key.\n",
      " |      \n",
      " |      For each row in the left DataFrame:\n",
      " |      \n",
      " |        - A \"backward\" search selects the last row in the right DataFrame whose\n",
      " |          'on' key is less than or equal to the left's key.\n",
      " |      \n",
      " |        - A \"forward\" search selects the first row in the right DataFrame whose\n",
      " |          'on' key is greater than or equal to the left's key.\n",
      " |      \n",
      " |          A \"nearest\" search selects the last row in the right DataFrame whose value\n",
      " |          is nearest to the left's key. String keys are not currently supported for a\n",
      " |          nearest search.\n",
      " |      \n",
      " |      The default is \"backward\".\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other\n",
      " |          Lazy DataFrame to join with.\n",
      " |      left_on\n",
      " |          Join column of the left DataFrame.\n",
      " |      right_on\n",
      " |          Join column of the right DataFrame.\n",
      " |      on\n",
      " |          Join column of both DataFrames. If set, `left_on` and `right_on` should be\n",
      " |          None.\n",
      " |      by\n",
      " |          Join on these columns before doing asof join.\n",
      " |      by_left\n",
      " |          Join on these columns before doing asof join.\n",
      " |      by_right\n",
      " |          Join on these columns before doing asof join.\n",
      " |      strategy : {'backward', 'forward', 'nearest'}\n",
      " |          Join strategy.\n",
      " |      suffix\n",
      " |          Suffix to append to columns with a duplicate name.\n",
      " |      tolerance\n",
      " |          Numeric tolerance. By setting this the join will only be done if the near\n",
      " |          keys are within this distance. If an asof join is done on columns of dtype\n",
      " |          \"Date\", \"Datetime\", \"Duration\" or \"Time\", use either a datetime.timedelta\n",
      " |          object or the following string language:\n",
      " |      \n",
      " |              - 1ns   (1 nanosecond)\n",
      " |              - 1us   (1 microsecond)\n",
      " |              - 1ms   (1 millisecond)\n",
      " |              - 1s    (1 second)\n",
      " |              - 1m    (1 minute)\n",
      " |              - 1h    (1 hour)\n",
      " |              - 1d    (1 calendar day)\n",
      " |              - 1w    (1 calendar week)\n",
      " |              - 1mo   (1 calendar month)\n",
      " |              - 1q    (1 calendar quarter)\n",
      " |              - 1y    (1 calendar year)\n",
      " |              - 1i    (1 index count)\n",
      " |      \n",
      " |              Or combine them:\n",
      " |              \"3d12h4m25s\" # 3 days, 12 hours, 4 minutes, and 25 seconds\n",
      " |      \n",
      " |              By \"calendar day\", we mean the corresponding time on the next day\n",
      " |              (which may not be 24 hours, due to daylight savings). Similarly for\n",
      " |              \"calendar week\", \"calendar month\", \"calendar quarter\", and\n",
      " |              \"calendar year\".\n",
      " |      \n",
      " |      allow_parallel\n",
      " |          Allow the physical plan to optionally evaluate the computation of both\n",
      " |          DataFrames up to the join in parallel.\n",
      " |      force_parallel\n",
      " |          Force the physical plan to evaluate the computation of both DataFrames up to\n",
      " |          the join in parallel.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from datetime import datetime\n",
      " |      >>> gdp = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"date\": [\n",
      " |      ...             datetime(2016, 1, 1),\n",
      " |      ...             datetime(2017, 1, 1),\n",
      " |      ...             datetime(2018, 1, 1),\n",
      " |      ...             datetime(2019, 1, 1),\n",
      " |      ...         ],  # note record date: Jan 1st (sorted!)\n",
      " |      ...         \"gdp\": [4164, 4411, 4566, 4696],\n",
      " |      ...     }\n",
      " |      ... ).set_sorted(\"date\")\n",
      " |      >>> population = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"date\": [\n",
      " |      ...             datetime(2016, 5, 12),\n",
      " |      ...             datetime(2017, 5, 12),\n",
      " |      ...             datetime(2018, 5, 12),\n",
      " |      ...             datetime(2019, 5, 12),\n",
      " |      ...         ],  # note record date: May 12th (sorted!)\n",
      " |      ...         \"population\": [82.19, 82.66, 83.12, 83.52],\n",
      " |      ...     }\n",
      " |      ... ).set_sorted(\"date\")\n",
      " |      >>> population.join_asof(gdp, on=\"date\", strategy=\"backward\").collect()\n",
      " |      shape: (4, 3)\n",
      " |      ┌─────────────────────┬────────────┬──────┐\n",
      " |      │ date                ┆ population ┆ gdp  │\n",
      " |      │ ---                 ┆ ---        ┆ ---  │\n",
      " |      │ datetime[μs]        ┆ f64        ┆ i64  │\n",
      " |      ╞═════════════════════╪════════════╪══════╡\n",
      " |      │ 2016-05-12 00:00:00 ┆ 82.19      ┆ 4164 │\n",
      " |      │ 2017-05-12 00:00:00 ┆ 82.66      ┆ 4411 │\n",
      " |      │ 2018-05-12 00:00:00 ┆ 83.12      ┆ 4566 │\n",
      " |      │ 2019-05-12 00:00:00 ┆ 83.52      ┆ 4696 │\n",
      " |      └─────────────────────┴────────────┴──────┘\n",
      " |  \n",
      " |  last(self) -> 'Self'\n",
      " |      Get the last row of the DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 3, 5],\n",
      " |      ...         \"b\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.last().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 5   ┆ 6   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  lazy(self) -> 'Self'\n",
      " |      Return lazy representation, i.e. itself.\n",
      " |      \n",
      " |      Useful for writing code that expects either a :class:`DataFrame` or\n",
      " |      :class:`LazyFrame`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [None, 2, 3, 4],\n",
      " |      ...         \"b\": [0.5, None, 2.5, 13],\n",
      " |      ...         \"c\": [True, True, False, None],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.lazy()  # doctest: +ELLIPSIS\n",
      " |      <LazyFrame [3 cols, {\"a\": Int64 … \"c\": Boolean}] at ...>\n",
      " |  \n",
      " |  limit(self, n: 'int' = 5) -> 'Self'\n",
      " |      Get the first `n` rows.\n",
      " |      \n",
      " |      Alias for :func:`LazyFrame.head`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Number of rows to return.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Consider using the :func:`fetch` operation if you only want to test your\n",
      " |      query. The :func:`fetch` operation will load the first `n` rows at the scan\n",
      " |      level, whereas the :func:`head`/:func:`limit` are applied at the end.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"b\": [7, 8, 9, 10, 11, 12],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.limit().collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 7   │\n",
      " |      │ 2   ┆ 8   │\n",
      " |      │ 3   ┆ 9   │\n",
      " |      │ 4   ┆ 10  │\n",
      " |      │ 5   ┆ 11  │\n",
      " |      └─────┴─────┘\n",
      " |      >>> lf.limit(2).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 7   │\n",
      " |      │ 2   ┆ 8   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  map(self, function: 'Callable[[DataFrame], DataFrame]', *, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, slice_pushdown: 'bool' = True, no_optimizations: 'bool' = False, schema: 'None | SchemaDict' = None, validate_output_schema: 'bool' = True, streamable: 'bool' = False) -> 'Self'\n",
      " |      Apply a custom function.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.0\n",
      " |          This method has been renamed to :func:`LazyFrame.map_batches`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      function\n",
      " |          Lambda/ function to apply.\n",
      " |      predicate_pushdown\n",
      " |          Allow predicate pushdown optimization to pass this node.\n",
      " |      projection_pushdown\n",
      " |          Allow projection pushdown optimization to pass this node.\n",
      " |      slice_pushdown\n",
      " |          Allow slice pushdown optimization to pass this node.\n",
      " |      no_optimizations\n",
      " |          Turn off all optimizations past this point.\n",
      " |      schema\n",
      " |          Output schema of the function, if set to `None` we assume that the schema\n",
      " |          will remain unchanged by the applied function.\n",
      " |      validate_output_schema\n",
      " |          It is paramount that polars' schema is correct. This flag will ensure that\n",
      " |          the output schema of this function will be checked with the expected schema.\n",
      " |          Setting this to `False` will not do this check, but may lead to hard to\n",
      " |          debug bugs.\n",
      " |      streamable\n",
      " |          Whether the function that is given is eligible to be running with the\n",
      " |          streaming engine. That means that the function must produce the same result\n",
      " |          when it is executed in batches or when it is be executed on the full\n",
      " |          dataset.\n",
      " |  \n",
      " |  map_batches(self, function: 'Callable[[DataFrame], DataFrame]', *, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, slice_pushdown: 'bool' = True, no_optimizations: 'bool' = False, schema: 'None | SchemaDict' = None, validate_output_schema: 'bool' = True, streamable: 'bool' = False) -> 'Self'\n",
      " |      Apply a custom function.\n",
      " |      \n",
      " |      It is important that the function returns a Polars DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      function\n",
      " |          Lambda/ function to apply.\n",
      " |      predicate_pushdown\n",
      " |          Allow predicate pushdown optimization to pass this node.\n",
      " |      projection_pushdown\n",
      " |          Allow projection pushdown optimization to pass this node.\n",
      " |      slice_pushdown\n",
      " |          Allow slice pushdown optimization to pass this node.\n",
      " |      no_optimizations\n",
      " |          Turn off all optimizations past this point.\n",
      " |      schema\n",
      " |          Output schema of the function, if set to `None` we assume that the schema\n",
      " |          will remain unchanged by the applied function.\n",
      " |      validate_output_schema\n",
      " |          It is paramount that polars' schema is correct. This flag will ensure that\n",
      " |          the output schema of this function will be checked with the expected schema.\n",
      " |          Setting this to `False` will not do this check, but may lead to hard to\n",
      " |          debug bugs.\n",
      " |      streamable\n",
      " |          Whether the function that is given is eligible to be running with the\n",
      " |          streaming engine. That means that the function must produce the same result\n",
      " |          when it is executed in batches or when it is be executed on the full\n",
      " |          dataset.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      The `schema` of a `LazyFrame` must always be correct. It is up to the caller\n",
      " |      of this function to ensure that this invariant is upheld.\n",
      " |      \n",
      " |      It is important that the optimization flags are correct. If the custom function\n",
      " |      for instance does an aggregation of a column, `predicate_pushdown` should not\n",
      " |      be allowed, as this prunes rows and will influence your aggregation results.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = (  # doctest: +SKIP\n",
      " |      ...     pl.LazyFrame(\n",
      " |      ...         {\n",
      " |      ...             \"a\": pl.int_range(-100_000, 0, eager=True),\n",
      " |      ...             \"b\": pl.int_range(0, 100_000, eager=True),\n",
      " |      ...         }\n",
      " |      ...     )\n",
      " |      ...     .map_batches(lambda x: 2 * x, streamable=True)\n",
      " |      ...     .collect(streaming=True)\n",
      " |      ... )\n",
      " |      shape: (100_000, 2)\n",
      " |      ┌─────────┬────────┐\n",
      " |      │ a       ┆ b      │\n",
      " |      │ ---     ┆ ---    │\n",
      " |      │ i64     ┆ i64    │\n",
      " |      ╞═════════╪════════╡\n",
      " |      │ -200000 ┆ 0      │\n",
      " |      │ -199998 ┆ 2      │\n",
      " |      │ -199996 ┆ 4      │\n",
      " |      │ -199994 ┆ 6      │\n",
      " |      │ …       ┆ …      │\n",
      " |      │ -8      ┆ 199992 │\n",
      " |      │ -6      ┆ 199994 │\n",
      " |      │ -4      ┆ 199996 │\n",
      " |      │ -2      ┆ 199998 │\n",
      " |      └─────────┴────────┘\n",
      " |  \n",
      " |  max(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their maximum value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.max().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 4   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  mean(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their mean value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.mean().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ a   ┆ b    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ f64 ┆ f64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 2.5 ┆ 1.25 │\n",
      " |      └─────┴──────┘\n",
      " |  \n",
      " |  median(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their median value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.median().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ f64 ┆ f64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 2.5 ┆ 1.0 │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  melt(self, id_vars: 'ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None' = None, value_vars: 'ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None' = None, variable_name: 'str | None' = None, value_name: 'str | None' = None, *, streamable: 'bool' = True) -> 'Self'\n",
      " |      Unpivot a DataFrame from wide to long format.\n",
      " |      \n",
      " |      Optionally leaves identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one or more\n",
      " |      columns are identifier variables (id_vars) while all other columns, considered\n",
      " |      measured variables (value_vars), are \"unpivoted\" to the row axis leaving just\n",
      " |      two non-identifier columns, 'variable' and 'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars\n",
      " |          Column(s) or selector(s) to use as identifier variables.\n",
      " |      value_vars\n",
      " |          Column(s) or selector(s) to use as values variables; if `value_vars`\n",
      " |          is empty all columns that are not in `id_vars` will be used.\n",
      " |      variable_name\n",
      " |          Name to give to the `variable` column. Defaults to \"variable\"\n",
      " |      value_name\n",
      " |          Name to give to the `value` column. Defaults to \"value\"\n",
      " |      streamable\n",
      " |          Allow this node to run in the streaming engine.\n",
      " |          If this runs in streaming, the output of the melt operation\n",
      " |          will not have a stable ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"x\", \"y\", \"z\"],\n",
      " |      ...         \"b\": [1, 3, 5],\n",
      " |      ...         \"c\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> import polars.selectors as cs\n",
      " |      >>> lf.melt(id_vars=\"a\", value_vars=cs.numeric()).collect()\n",
      " |      shape: (6, 3)\n",
      " |      ┌─────┬──────────┬───────┐\n",
      " |      │ a   ┆ variable ┆ value │\n",
      " |      │ --- ┆ ---      ┆ ---   │\n",
      " |      │ str ┆ str      ┆ i64   │\n",
      " |      ╞═════╪══════════╪═══════╡\n",
      " |      │ x   ┆ b        ┆ 1     │\n",
      " |      │ y   ┆ b        ┆ 3     │\n",
      " |      │ z   ┆ b        ┆ 5     │\n",
      " |      │ x   ┆ c        ┆ 2     │\n",
      " |      │ y   ┆ c        ┆ 4     │\n",
      " |      │ z   ┆ c        ┆ 6     │\n",
      " |      └─────┴──────────┴───────┘\n",
      " |  \n",
      " |  merge_sorted(self, other: 'LazyFrame', key: 'str') -> 'Self'\n",
      " |      Take two sorted DataFrames and merge them by the sorted key.\n",
      " |      \n",
      " |      The output of this operation will also be sorted.\n",
      " |      It is the callers responsibility that the frames are sorted\n",
      " |      by that key otherwise the output will not make sense.\n",
      " |      \n",
      " |      The schemas of both LazyFrames must be equal.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other\n",
      " |          Other DataFrame that must be merged\n",
      " |      key\n",
      " |          Key that is sorted.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df0 = pl.LazyFrame(\n",
      " |      ...     {\"name\": [\"steve\", \"elise\", \"bob\"], \"age\": [42, 44, 18]}\n",
      " |      ... ).sort(\"age\")\n",
      " |      >>> df0.collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌───────┬─────┐\n",
      " |      │ name  ┆ age │\n",
      " |      │ ---   ┆ --- │\n",
      " |      │ str   ┆ i64 │\n",
      " |      ╞═══════╪═════╡\n",
      " |      │ bob   ┆ 18  │\n",
      " |      │ steve ┆ 42  │\n",
      " |      │ elise ┆ 44  │\n",
      " |      └───────┴─────┘\n",
      " |      >>> df1 = pl.LazyFrame(\n",
      " |      ...     {\"name\": [\"anna\", \"megan\", \"steve\", \"thomas\"], \"age\": [21, 33, 42, 20]}\n",
      " |      ... ).sort(\"age\")\n",
      " |      >>> df1.collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌────────┬─────┐\n",
      " |      │ name   ┆ age │\n",
      " |      │ ---    ┆ --- │\n",
      " |      │ str    ┆ i64 │\n",
      " |      ╞════════╪═════╡\n",
      " |      │ thomas ┆ 20  │\n",
      " |      │ anna   ┆ 21  │\n",
      " |      │ megan  ┆ 33  │\n",
      " |      │ steve  ┆ 42  │\n",
      " |      └────────┴─────┘\n",
      " |      >>> df0.merge_sorted(df1, key=\"age\").collect()\n",
      " |      shape: (7, 2)\n",
      " |      ┌────────┬─────┐\n",
      " |      │ name   ┆ age │\n",
      " |      │ ---    ┆ --- │\n",
      " |      │ str    ┆ i64 │\n",
      " |      ╞════════╪═════╡\n",
      " |      │ bob    ┆ 18  │\n",
      " |      │ thomas ┆ 20  │\n",
      " |      │ anna   ┆ 21  │\n",
      " |      │ megan  ┆ 33  │\n",
      " |      │ steve  ┆ 42  │\n",
      " |      │ steve  ┆ 42  │\n",
      " |      │ elise  ┆ 44  │\n",
      " |      └────────┴─────┘\n",
      " |  \n",
      " |  min(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their minimum value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.min().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 1   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  null_count(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame as the sum of their null value count.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, None, 3],\n",
      " |      ...         \"bar\": [6, 7, None],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.null_count().collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ u32 ┆ u32 ┆ u32 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 1   ┆ 0   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  pipe(self, function: 'Callable[Concatenate[LazyFrame, P], T]', *args: 'P.args', **kwargs: 'P.kwargs') -> 'T'\n",
      " |      Offers a structured way to apply a sequence of user-defined functions (UDFs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      function\n",
      " |          Callable; will receive the frame as the first parameter,\n",
      " |          followed by any given args/kwargs.\n",
      " |      *args\n",
      " |          Arguments to pass to the UDF.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to the UDF.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def cast_str_to_int(data, col_name):\n",
      " |      ...     return data.with_columns(pl.col(col_name).cast(pl.Int64))\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [\"10\", \"20\", \"30\", \"40\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.pipe(cast_str_to_int, col_name=\"b\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 10  │\n",
      " |      │ 2   ┆ 20  │\n",
      " |      │ 3   ┆ 30  │\n",
      " |      │ 4   ┆ 40  │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"b\": [1, 2],\n",
      " |      ...         \"a\": [3, 4],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ b   ┆ a   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 3   │\n",
      " |      │ 2   ┆ 4   │\n",
      " |      └─────┴─────┘\n",
      " |      >>> lf.pipe(lambda tdf: tdf.select(sorted(tdf.columns))).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 3   ┆ 1   │\n",
      " |      │ 4   ┆ 2   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  profile(self, *, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, no_optimization: 'bool' = False, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, show_plot: 'bool' = False, truncate_nodes: 'int' = 0, figsize: 'tuple[int, int]' = (18, 8), streaming: 'bool' = False) -> 'tuple[DataFrame, DataFrame]'\n",
      " |      Profile a LazyFrame.\n",
      " |      \n",
      " |      This will run the query and return a tuple\n",
      " |      containing the materialized DataFrame and a DataFrame that\n",
      " |      contains profiling information of each node that is executed.\n",
      " |      \n",
      " |      The units of the timings are microseconds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      show_plot\n",
      " |          Show a gantt chart of the profiling result\n",
      " |      truncate_nodes\n",
      " |          Truncate the label lengths in the gantt chart to this number of\n",
      " |          characters.\n",
      " |      figsize\n",
      " |          matplotlib figsize of the profiling plot\n",
      " |      streaming\n",
      " |          Run parts of the query in a streaming fashion (this is in an alpha state)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\", maintain_order=True).agg(pl.all().sum()).sort(\n",
      " |      ...     \"a\"\n",
      " |      ... ).profile()  # doctest: +SKIP\n",
      " |      (shape: (3, 3)\n",
      " |       ┌─────┬─────┬─────┐\n",
      " |       │ a   ┆ b   ┆ c   │\n",
      " |       │ --- ┆ --- ┆ --- │\n",
      " |       │ str ┆ i64 ┆ i64 │\n",
      " |       ╞═════╪═════╪═════╡\n",
      " |       │ a   ┆ 4   ┆ 10  │\n",
      " |       │ b   ┆ 11  ┆ 10  │\n",
      " |       │ c   ┆ 6   ┆ 1   │\n",
      " |       └─────┴─────┴─────┘,\n",
      " |       shape: (3, 3)\n",
      " |       ┌─────────────────────────┬───────┬──────┐\n",
      " |       │ node                    ┆ start ┆ end  │\n",
      " |       │ ---                     ┆ ---   ┆ ---  │\n",
      " |       │ str                     ┆ u64   ┆ u64  │\n",
      " |       ╞═════════════════════════╪═══════╪══════╡\n",
      " |       │ optimization            ┆ 0     ┆ 5    │\n",
      " |       │ group_by_partitioned(a) ┆ 5     ┆ 470  │\n",
      " |       │ sort(a)                 ┆ 475   ┆ 1964 │\n",
      " |       └─────────────────────────┴───────┴──────┘)\n",
      " |  \n",
      " |  quantile(self, quantile: 'float | Expr', interpolation: 'RollingInterpolationMethod' = 'nearest') -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their quantile value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      quantile\n",
      " |          Quantile between 0.0 and 1.0.\n",
      " |      interpolation : {'nearest', 'higher', 'lower', 'midpoint', 'linear'}\n",
      " |          Interpolation method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.quantile(0.7).collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ f64 ┆ f64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 3.0 ┆ 1.0 │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  rename(self, mapping: 'dict[str, str] | Callable[[str], str]') -> 'Self'\n",
      " |      Rename column names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapping\n",
      " |          Key value pairs that map from old name to new name, or a function\n",
      " |          that takes the old name as input and returns the new name.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If existing names are swapped (e.g. 'A' points to 'B' and 'B' points to 'A'),\n",
      " |      polars will block projection and predicate pushdowns at this node.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6, 7, 8],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.rename({\"foo\": \"apple\"}).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌───────┬─────┬─────┐\n",
      " |      │ apple ┆ bar ┆ ham │\n",
      " |      │ ---   ┆ --- ┆ --- │\n",
      " |      │ i64   ┆ i64 ┆ str │\n",
      " |      ╞═══════╪═════╪═════╡\n",
      " |      │ 1     ┆ 6   ┆ a   │\n",
      " |      │ 2     ┆ 7   ┆ b   │\n",
      " |      │ 3     ┆ 8   ┆ c   │\n",
      " |      └───────┴─────┴─────┘\n",
      " |      >>> lf.rename(lambda column_name: \"c\" + column_name[1:]).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ coo ┆ car ┆ cam │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ 6   ┆ a   │\n",
      " |      │ 2   ┆ 7   ┆ b   │\n",
      " |      │ 3   ┆ 8   ┆ c   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  reverse(self) -> 'Self'\n",
      " |      Reverse the DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"key\": [\"a\", \"b\", \"c\"],\n",
      " |      ...         \"val\": [1, 2, 3],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.reverse().collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ key ┆ val │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ c   ┆ 3   │\n",
      " |      │ b   ┆ 2   │\n",
      " |      │ a   ┆ 1   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  rolling(self, index_column: 'IntoExpr', *, period: 'str | timedelta', offset: 'str | timedelta | None' = None, closed: 'ClosedInterval' = 'right', by: 'IntoExpr | Iterable[IntoExpr] | None' = None, check_sorted: 'bool' = True) -> 'LazyGroupBy'\n",
      " |      Create rolling groups based on a time, Int32, or Int64 column.\n",
      " |      \n",
      " |      Different from a `dynamic_group_by` the windows are now determined by the\n",
      " |      individual values and are not of constant intervals. For constant intervals\n",
      " |      use :func:`LazyFrame.group_by_dynamic`.\n",
      " |      \n",
      " |      If you have a time series `<t_0, t_1, ..., t_n>`, then by default the\n",
      " |      windows created will be\n",
      " |      \n",
      " |          * (t_0 - period, t_0]\n",
      " |          * (t_1 - period, t_1]\n",
      " |          * ...\n",
      " |          * (t_n - period, t_n]\n",
      " |      \n",
      " |      whereas if you pass a non-default `offset`, then the windows will be\n",
      " |      \n",
      " |          * (t_0 + offset, t_0 + offset + period]\n",
      " |          * (t_1 + offset, t_1 + offset + period]\n",
      " |          * ...\n",
      " |          * (t_n + offset, t_n + offset + period]\n",
      " |      \n",
      " |      The `period` and `offset` arguments are created either from a timedelta, or\n",
      " |      by using the following string language:\n",
      " |      \n",
      " |      - 1ns   (1 nanosecond)\n",
      " |      - 1us   (1 microsecond)\n",
      " |      - 1ms   (1 millisecond)\n",
      " |      - 1s    (1 second)\n",
      " |      - 1m    (1 minute)\n",
      " |      - 1h    (1 hour)\n",
      " |      - 1d    (1 calendar day)\n",
      " |      - 1w    (1 calendar week)\n",
      " |      - 1mo   (1 calendar month)\n",
      " |      - 1q    (1 calendar quarter)\n",
      " |      - 1y    (1 calendar year)\n",
      " |      - 1i    (1 index count)\n",
      " |      \n",
      " |      Or combine them:\n",
      " |      \"3d12h4m25s\" # 3 days, 12 hours, 4 minutes, and 25 seconds\n",
      " |      \n",
      " |      By \"calendar day\", we mean the corresponding time on the next day (which may\n",
      " |      not be 24 hours, due to daylight savings). Similarly for \"calendar week\",\n",
      " |      \"calendar month\", \"calendar quarter\", and \"calendar year\".\n",
      " |      \n",
      " |      In case of a rolling operation on an integer column, the windows are defined by:\n",
      " |      \n",
      " |      - \"1i\"      # length 1\n",
      " |      - \"10i\"     # length 10\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index_column\n",
      " |          Column used to group based on the time window.\n",
      " |          Often of type Date/Datetime.\n",
      " |          This column must be sorted in ascending order (or, if `by` is specified,\n",
      " |          then it must be sorted in ascending order within each group).\n",
      " |      \n",
      " |          In case of a rolling group by on indices, dtype needs to be one of\n",
      " |          {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\n",
      " |          performance matters use an Int64 column.\n",
      " |      period\n",
      " |          length of the window - must be non-negative\n",
      " |      offset\n",
      " |          offset of the window. Default is -period\n",
      " |      closed : {'right', 'left', 'both', 'none'}\n",
      " |          Define which sides of the temporal interval are closed (inclusive).\n",
      " |      by\n",
      " |          Also group by this column/these columns\n",
      " |      check_sorted\n",
      " |          When the `by` argument is given, polars can not check sortedness\n",
      " |          by the metadata and has to do a full scan on the index column to\n",
      " |          verify data is sorted. This is expensive. If you are sure the\n",
      " |          data within the by groups is sorted, you can set this to `False`.\n",
      " |          Doing so incorrectly will lead to incorrect output\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyGroupBy\n",
      " |          Object you can call `.agg` on to aggregate by groups, the result\n",
      " |          of which will be sorted by `index_column` (but note that if `by` columns are\n",
      " |          passed, it will only be sorted within each `by` group).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      group_by_dynamic\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dates = [\n",
      " |      ...     \"2020-01-01 13:45:48\",\n",
      " |      ...     \"2020-01-01 16:42:13\",\n",
      " |      ...     \"2020-01-01 16:45:09\",\n",
      " |      ...     \"2020-01-02 18:12:48\",\n",
      " |      ...     \"2020-01-03 19:45:32\",\n",
      " |      ...     \"2020-01-08 23:16:43\",\n",
      " |      ... ]\n",
      " |      >>> df = pl.LazyFrame({\"dt\": dates, \"a\": [3, 7, 5, 9, 2, 1]}).with_columns(\n",
      " |      ...     pl.col(\"dt\").str.strptime(pl.Datetime).set_sorted()\n",
      " |      ... )\n",
      " |      >>> out = (\n",
      " |      ...     df.rolling(index_column=\"dt\", period=\"2d\")\n",
      " |      ...     .agg(\n",
      " |      ...         pl.sum(\"a\").alias(\"sum_a\"),\n",
      " |      ...         pl.min(\"a\").alias(\"min_a\"),\n",
      " |      ...         pl.max(\"a\").alias(\"max_a\"),\n",
      " |      ...     )\n",
      " |      ...     .collect()\n",
      " |      ... )\n",
      " |      >>> out\n",
      " |      shape: (6, 4)\n",
      " |      ┌─────────────────────┬───────┬───────┬───────┐\n",
      " |      │ dt                  ┆ sum_a ┆ min_a ┆ max_a │\n",
      " |      │ ---                 ┆ ---   ┆ ---   ┆ ---   │\n",
      " |      │ datetime[μs]        ┆ i64   ┆ i64   ┆ i64   │\n",
      " |      ╞═════════════════════╪═══════╪═══════╪═══════╡\n",
      " |      │ 2020-01-01 13:45:48 ┆ 3     ┆ 3     ┆ 3     │\n",
      " |      │ 2020-01-01 16:42:13 ┆ 10    ┆ 3     ┆ 7     │\n",
      " |      │ 2020-01-01 16:45:09 ┆ 15    ┆ 3     ┆ 7     │\n",
      " |      │ 2020-01-02 18:12:48 ┆ 24    ┆ 3     ┆ 9     │\n",
      " |      │ 2020-01-03 19:45:32 ┆ 11    ┆ 2     ┆ 9     │\n",
      " |      │ 2020-01-08 23:16:43 ┆ 1     ┆ 1     ┆ 1     │\n",
      " |      └─────────────────────┴───────┴───────┴───────┘\n",
      " |  \n",
      " |  select(self, *exprs: 'IntoExpr | Iterable[IntoExpr]', **named_exprs: 'IntoExpr') -> 'Self'\n",
      " |      Select columns from this LazyFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *exprs\n",
      " |          Column(s) to select, specified as positional arguments.\n",
      " |          Accepts expression input. Strings are parsed as column names,\n",
      " |          other non-expression inputs are parsed as literals.\n",
      " |      **named_exprs\n",
      " |          Additional columns to select, specified as keyword arguments.\n",
      " |          The columns will be renamed to the keyword used.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Pass the name of a column to select that column.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6, 7, 8],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.select(\"foo\").collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌─────┐\n",
      " |      │ foo │\n",
      " |      │ --- │\n",
      " |      │ i64 │\n",
      " |      ╞═════╡\n",
      " |      │ 1   │\n",
      " |      │ 2   │\n",
      " |      │ 3   │\n",
      " |      └─────┘\n",
      " |      \n",
      " |      Multiple columns can be selected by passing a list of column names.\n",
      " |      \n",
      " |      >>> lf.select([\"foo\", \"bar\"]).collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ foo ┆ bar │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 6   │\n",
      " |      │ 2   ┆ 7   │\n",
      " |      │ 3   ┆ 8   │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Multiple columns can also be selected using positional arguments instead of a\n",
      " |      list. Expressions are also accepted.\n",
      " |      \n",
      " |      >>> lf.select(pl.col(\"foo\"), pl.col(\"bar\") + 1).collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ foo ┆ bar │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 7   │\n",
      " |      │ 2   ┆ 8   │\n",
      " |      │ 3   ┆ 9   │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Use keyword arguments to easily name your expression inputs.\n",
      " |      \n",
      " |      >>> lf.select(\n",
      " |      ...     threshold=pl.when(pl.col(\"foo\") > 2).then(10).otherwise(0)\n",
      " |      ... ).collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌───────────┐\n",
      " |      │ threshold │\n",
      " |      │ ---       │\n",
      " |      │ i32       │\n",
      " |      ╞═══════════╡\n",
      " |      │ 0         │\n",
      " |      │ 0         │\n",
      " |      │ 10        │\n",
      " |      └───────────┘\n",
      " |      \n",
      " |      Expressions with multiple outputs can be automatically instantiated as Structs\n",
      " |      by enabling the setting `Config.set_auto_structify(True)`:\n",
      " |      \n",
      " |      >>> with pl.Config(auto_structify=True):\n",
      " |      ...     lf.select(\n",
      " |      ...         is_odd=(pl.col(pl.INTEGER_DTYPES) % 2).name.suffix(\"_is_odd\"),\n",
      " |      ...     ).collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌───────────┐\n",
      " |      │ is_odd    │\n",
      " |      │ ---       │\n",
      " |      │ struct[2] │\n",
      " |      ╞═══════════╡\n",
      " |      │ {1,0}     │\n",
      " |      │ {0,1}     │\n",
      " |      │ {1,0}     │\n",
      " |      └───────────┘\n",
      " |  \n",
      " |  select_seq(self, *exprs: 'IntoExpr | Iterable[IntoExpr]', **named_exprs: 'IntoExpr') -> 'Self'\n",
      " |      Select columns from this LazyFrame.\n",
      " |      \n",
      " |      This will run all expression sequentially instead of in parallel.\n",
      " |      Use this when the work per expression is cheap.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *exprs\n",
      " |          Column(s) to select, specified as positional arguments.\n",
      " |          Accepts expression input. Strings are parsed as column names,\n",
      " |          other non-expression inputs are parsed as literals.\n",
      " |      **named_exprs\n",
      " |          Additional columns to select, specified as keyword arguments.\n",
      " |          The columns will be renamed to the keyword used.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      select\n",
      " |  \n",
      " |  serialize(self, file: 'IOBase | str | Path | None' = None) -> 'str | None'\n",
      " |      Serialize the logical plan of this LazyFrame to a file or string in JSON format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      file\n",
      " |          File path to which the result should be written. If set to `None`\n",
      " |          (default), the output is returned as a string instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LazyFrame.deserialize\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Serialize the logical plan into a JSON string.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame({\"a\": [1, 2, 3]}).sum()\n",
      " |      >>> json = lf.serialize()\n",
      " |      >>> json\n",
      " |      '{\"Projection\":{\"expr\":[{\"Agg\":{\"Sum\":{\"Column\":\"a\"}}}],\"input\":{\"DataFrameScan\":{\"df\":{\"columns\":[{\"name\":\"a\",\"datatype\":\"Int64\",\"bit_settings\":\"\",\"values\":[1,2,3]}]},\"schema\":{\"inner\":{\"a\":\"Int64\"}},\"output_schema\":null,\"projection\":null,\"selection\":null}},\"schema\":{\"inner\":{\"a\":\"Int64\"}},\"options\":{\"run_parallel\":true,\"duplicate_check\":true}}}'\n",
      " |      \n",
      " |      The logical plan can later be deserialized back into a LazyFrame.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> pl.LazyFrame.deserialize(io.StringIO(json)).collect()\n",
      " |      shape: (1, 1)\n",
      " |      ┌─────┐\n",
      " |      │ a   │\n",
      " |      │ --- │\n",
      " |      │ i64 │\n",
      " |      ╞═════╡\n",
      " |      │ 6   │\n",
      " |      └─────┘\n",
      " |  \n",
      " |  set_sorted(self, column: 'str | Iterable[str]', *more_columns: 'str', descending: 'bool' = False) -> 'Self'\n",
      " |      Indicate that one or multiple columns are sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column\n",
      " |          Columns that are sorted\n",
      " |      more_columns\n",
      " |          Additional columns that are sorted, specified as positional arguments.\n",
      " |      descending\n",
      " |          Whether the columns are sorted in descending order.\n",
      " |  \n",
      " |  shift(self, n: 'int | IntoExprColumn' = 1, *, fill_value: 'IntoExpr | None' = None) -> 'Self'\n",
      " |      Shift values by the given number of indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Number of indices to shift forward. If a negative value is passed, values\n",
      " |          are shifted in the opposite direction instead.\n",
      " |      fill_value\n",
      " |          Fill the resulting null values with this value. Accepts expression input.\n",
      " |          Non-expression inputs are parsed as literals.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is similar to the `LAG` operation in SQL when the value for `n`\n",
      " |      is positive. With a negative value for `n`, it is similar to `LEAD`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, values are shifted forward by one index.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [5, 6, 7, 8],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.shift().collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌──────┬──────┐\n",
      " |      │ a    ┆ b    │\n",
      " |      │ ---  ┆ ---  │\n",
      " |      │ i64  ┆ i64  │\n",
      " |      ╞══════╪══════╡\n",
      " |      │ null ┆ null │\n",
      " |      │ 1    ┆ 5    │\n",
      " |      │ 2    ┆ 6    │\n",
      " |      │ 3    ┆ 7    │\n",
      " |      └──────┴──────┘\n",
      " |      \n",
      " |      Pass a negative value to shift in the opposite direction instead.\n",
      " |      \n",
      " |      >>> lf.shift(-2).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌──────┬──────┐\n",
      " |      │ a    ┆ b    │\n",
      " |      │ ---  ┆ ---  │\n",
      " |      │ i64  ┆ i64  │\n",
      " |      ╞══════╪══════╡\n",
      " |      │ 3    ┆ 7    │\n",
      " |      │ 4    ┆ 8    │\n",
      " |      │ null ┆ null │\n",
      " |      │ null ┆ null │\n",
      " |      └──────┴──────┘\n",
      " |      \n",
      " |      Specify `fill_value` to fill the resulting null values.\n",
      " |      \n",
      " |      >>> lf.shift(-2, fill_value=100).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 3   ┆ 7   │\n",
      " |      │ 4   ┆ 8   │\n",
      " |      │ 100 ┆ 100 │\n",
      " |      │ 100 ┆ 100 │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  shift_and_fill(self, fill_value: 'Expr | int | str | float', *, n: 'int' = 1) -> 'Self'\n",
      " |      Shift values by the given number of places and fill the resulting null values.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.12\n",
      " |          Use :func:`shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fill_value\n",
      " |          fill None values with the result of this expression.\n",
      " |      n\n",
      " |          Number of places to shift (may be negative).\n",
      " |  \n",
      " |  show_graph(self, *, optimized: 'bool' = True, show: 'bool' = True, output_path: 'str | Path | None' = None, raw_output: 'bool' = False, figsize: 'tuple[float, float]' = (16.0, 12.0), type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, streaming: 'bool' = False) -> 'str | None'\n",
      " |      Show a plot of the query plan. Note that you should have graphviz installed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      optimized\n",
      " |          Optimize the query plan.\n",
      " |      show\n",
      " |          Show the figure.\n",
      " |      output_path\n",
      " |          Write the figure to disk.\n",
      " |      raw_output\n",
      " |          Return dot syntax. This cannot be combined with `show` and/or `output_path`.\n",
      " |      figsize\n",
      " |          Passed to matplotlib if `show` == True.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      comm_subplan_elim\n",
      " |          Will try to cache branching subplans that occur on self-joins or unions.\n",
      " |      comm_subexpr_elim\n",
      " |          Common subexpressions will be cached and reused.\n",
      " |      streaming\n",
      " |          Run parts of the query in a streaming fashion (this is in an alpha state)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"c\": [6, 5, 4, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.group_by(\"a\", maintain_order=True).agg(pl.all().sum()).sort(\n",
      " |      ...     \"a\"\n",
      " |      ... ).show_graph()  # doctest: +SKIP\n",
      " |  \n",
      " |  sink_csv(self, path: 'str | Path', *, include_bom: 'bool' = False, include_header: 'bool' = True, separator: 'str' = ',', line_terminator: 'str' = '\\n', quote_char: 'str' = '\"', batch_size: 'int' = 1024, datetime_format: 'str | None' = None, date_format: 'str | None' = None, time_format: 'str | None' = None, float_precision: 'int | None' = None, null_value: 'str | None' = None, quote_style: 'CsvQuoteStyle | None' = None, maintain_order: 'bool' = True, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, no_optimization: 'bool' = False) -> 'DataFrame'\n",
      " |      Evaluate the query in streaming mode and write to a CSV file.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Streaming mode is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      This allows streaming results that are larger than RAM to be written to disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          File path to which the file should be written.\n",
      " |      include_bom\n",
      " |          Whether to include UTF-8 BOM in the CSV output.\n",
      " |      include_header\n",
      " |          Whether to include header in the CSV output.\n",
      " |      separator\n",
      " |          Separate CSV fields with this symbol.\n",
      " |      line_terminator\n",
      " |          String used to end each row.\n",
      " |      quote_char\n",
      " |          Byte to use as quoting character.\n",
      " |      batch_size\n",
      " |          Number of rows that will be processed per thread.\n",
      " |      datetime_format\n",
      " |          A format string, with the specifiers defined by the\n",
      " |          `chrono <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_\n",
      " |          Rust crate. If no format specified, the default fractional-second\n",
      " |          precision is inferred from the maximum timeunit found in the frame's\n",
      " |          Datetime cols (if any).\n",
      " |      date_format\n",
      " |          A format string, with the specifiers defined by the\n",
      " |          `chrono <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_\n",
      " |          Rust crate.\n",
      " |      time_format\n",
      " |          A format string, with the specifiers defined by the\n",
      " |          `chrono <https://docs.rs/chrono/latest/chrono/format/strftime/index.html>`_\n",
      " |          Rust crate.\n",
      " |      float_precision\n",
      " |          Number of decimal places to write, applied to both `Float32` and\n",
      " |          `Float64` datatypes.\n",
      " |      null_value\n",
      " |          A string representing null values (defaulting to the empty string).\n",
      " |      quote_style : {'necessary', 'always', 'non_numeric', 'never'}\n",
      " |          Determines the quoting strategy used.\n",
      " |      \n",
      " |          - necessary (default): This puts quotes around fields only when necessary.\n",
      " |            They are necessary when fields contain a quote,\n",
      " |            delimiter or record terminator.\n",
      " |            Quotes are also necessary when writing an empty record\n",
      " |            (which is indistinguishable from a record with one empty field).\n",
      " |            This is the default.\n",
      " |          - always: This puts quotes around every field. Always.\n",
      " |          - never: This never puts quotes around fields, even if that results in\n",
      " |            invalid CSV data (e.g.: by not quoting strings containing the\n",
      " |            separator).\n",
      " |          - non_numeric: This puts quotes around all fields that are non-numeric.\n",
      " |            Namely, when writing a field that does not parse as a valid float\n",
      " |            or integer, then quotes will be used even if they aren`t strictly\n",
      " |            necessary.\n",
      " |      maintain_order\n",
      " |          Maintain the order in which data is processed.\n",
      " |          Setting this to `False` will  be slightly faster.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.scan_csv(\"/path/to/my_larger_than_ram_file.csv\")  # doctest: +SKIP\n",
      " |      >>> lf.sink_csv(\"out.csv\")  # doctest: +SKIP\n",
      " |  \n",
      " |  sink_ipc(self, path: 'str | Path', *, compression: 'str | None' = 'zstd', maintain_order: 'bool' = True, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, no_optimization: 'bool' = False) -> 'DataFrame'\n",
      " |      Evaluate the query in streaming mode and write to an IPC file.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Streaming mode is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      This allows streaming results that are larger than RAM to be written to disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          File path to which the file should be written.\n",
      " |      compression : {'lz4', 'zstd'}\n",
      " |          Choose \"zstd\" for good compression performance.\n",
      " |          Choose \"lz4\" for fast compression/decompression.\n",
      " |      maintain_order\n",
      " |          Maintain the order in which data is processed.\n",
      " |          Setting this to `False` will  be slightly faster.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.scan_csv(\"/path/to/my_larger_than_ram_file.csv\")  # doctest: +SKIP\n",
      " |      >>> lf.sink_ipc(\"out.arrow\")  # doctest: +SKIP\n",
      " |  \n",
      " |  sink_ndjson(self, path: 'str | Path', *, maintain_order: 'bool' = True, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, no_optimization: 'bool' = False) -> 'DataFrame'\n",
      " |      Evaluate the query in streaming mode and write to an NDJSON file.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Streaming mode is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      This allows streaming results that are larger than RAM to be written to disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          File path to which the file should be written.\n",
      " |      maintain_order\n",
      " |          Maintain the order in which data is processed.\n",
      " |          Setting this to `False` will be slightly faster.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.scan_csv(\"/path/to/my_larger_than_ram_file.csv\")  # doctest: +SKIP\n",
      " |      >>> lf.sink_ndjson(\"out.ndjson\")  # doctest: +SKIP\n",
      " |  \n",
      " |  sink_parquet(self, path: 'str | Path', *, compression: 'str' = 'zstd', compression_level: 'int | None' = None, statistics: 'bool' = False, row_group_size: 'int | None' = None, data_pagesize_limit: 'int | None' = None, maintain_order: 'bool' = True, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, slice_pushdown: 'bool' = True, no_optimization: 'bool' = False) -> 'DataFrame'\n",
      " |      Evaluate the query in streaming mode and write to a Parquet file.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Streaming mode is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      This allows streaming results that are larger than RAM to be written to disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          File path to which the file should be written.\n",
      " |      compression : {'lz4', 'uncompressed', 'snappy', 'gzip', 'lzo', 'brotli', 'zstd'}\n",
      " |          Choose \"zstd\" for good compression performance.\n",
      " |          Choose \"lz4\" for fast compression/decompression.\n",
      " |          Choose \"snappy\" for more backwards compatibility guarantees\n",
      " |          when you deal with older parquet readers.\n",
      " |      compression_level\n",
      " |          The level of compression to use. Higher compression means smaller files on\n",
      " |          disk.\n",
      " |      \n",
      " |          - \"gzip\" : min-level: 0, max-level: 10.\n",
      " |          - \"brotli\" : min-level: 0, max-level: 11.\n",
      " |          - \"zstd\" : min-level: 1, max-level: 22.\n",
      " |      statistics\n",
      " |          Write statistics to the parquet headers. This requires extra compute.\n",
      " |      row_group_size\n",
      " |          Size of the row groups in number of rows.\n",
      " |          If None (default), the chunks of the `DataFrame` are\n",
      " |          used. Writing in smaller chunks may reduce memory pressure and improve\n",
      " |          writing speeds.\n",
      " |      data_pagesize_limit\n",
      " |          Size limit of individual data pages.\n",
      " |          If not set defaults to 1024 * 1024 bytes\n",
      " |      maintain_order\n",
      " |          Maintain the order in which data is processed.\n",
      " |          Setting this to `False` will  be slightly faster.\n",
      " |      type_coercion\n",
      " |          Do type coercion optimization.\n",
      " |      predicate_pushdown\n",
      " |          Do predicate pushdown optimization.\n",
      " |      projection_pushdown\n",
      " |          Do projection pushdown optimization.\n",
      " |      simplify_expression\n",
      " |          Run simplify expressions optimization.\n",
      " |      slice_pushdown\n",
      " |          Slice pushdown optimization.\n",
      " |      no_optimization\n",
      " |          Turn off (certain) optimizations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.scan_csv(\"/path/to/my_larger_than_ram_file.csv\")  # doctest: +SKIP\n",
      " |      >>> lf.sink_parquet(\"out.parquet\")  # doctest: +SKIP\n",
      " |  \n",
      " |  slice(self, offset: 'int', length: 'int | None' = None) -> 'Self'\n",
      " |      Get a slice of this DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset\n",
      " |          Start index. Negative indexing is supported.\n",
      " |      length\n",
      " |          Length of the slice. If set to `None`, all rows starting at the offset\n",
      " |          will be selected.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"x\", \"y\", \"z\"],\n",
      " |      ...         \"b\": [1, 3, 5],\n",
      " |      ...         \"c\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.slice(1, 2).collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ a   ┆ b   ┆ c   │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ str ┆ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ y   ┆ 3   ┆ 4   │\n",
      " |      │ z   ┆ 5   ┆ 6   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  sort(self, by: 'IntoExpr | Iterable[IntoExpr]', *more_by: 'IntoExpr', descending: 'bool | Sequence[bool]' = False, nulls_last: 'bool' = False, maintain_order: 'bool' = False) -> 'Self'\n",
      " |      Sort the LazyFrame by the given columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by\n",
      " |          Column(s) to sort by. Accepts expression input. Strings are parsed as column\n",
      " |          names.\n",
      " |      *more_by\n",
      " |          Additional columns to sort by, specified as positional arguments.\n",
      " |      descending\n",
      " |          Sort in descending order. When sorting by multiple columns, can be specified\n",
      " |          per column by passing a sequence of booleans.\n",
      " |      nulls_last\n",
      " |          Place null values last.\n",
      " |      maintain_order\n",
      " |          Whether the order should be maintained if elements are equal.\n",
      " |          Note that if `true` streaming is not possible and performance might be\n",
      " |          worse since this requires a stable search.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Pass a single column name to sort by that column.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, None],\n",
      " |      ...         \"b\": [6.0, 5.0, 4.0],\n",
      " |      ...         \"c\": [\"a\", \"c\", \"b\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.sort(\"a\").collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬─────┐\n",
      " |      │ a    ┆ b   ┆ c   │\n",
      " |      │ ---  ┆ --- ┆ --- │\n",
      " |      │ i64  ┆ f64 ┆ str │\n",
      " |      ╞══════╪═════╪═════╡\n",
      " |      │ null ┆ 4.0 ┆ b   │\n",
      " |      │ 1    ┆ 6.0 ┆ a   │\n",
      " |      │ 2    ┆ 5.0 ┆ c   │\n",
      " |      └──────┴─────┴─────┘\n",
      " |      \n",
      " |      Sorting by expressions is also supported.\n",
      " |      \n",
      " |      >>> lf.sort(pl.col(\"a\") + pl.col(\"b\") * 2, nulls_last=True).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬─────┐\n",
      " |      │ a    ┆ b   ┆ c   │\n",
      " |      │ ---  ┆ --- ┆ --- │\n",
      " |      │ i64  ┆ f64 ┆ str │\n",
      " |      ╞══════╪═════╪═════╡\n",
      " |      │ 2    ┆ 5.0 ┆ c   │\n",
      " |      │ 1    ┆ 6.0 ┆ a   │\n",
      " |      │ null ┆ 4.0 ┆ b   │\n",
      " |      └──────┴─────┴─────┘\n",
      " |      \n",
      " |      Sort by multiple columns by passing a list of columns.\n",
      " |      \n",
      " |      >>> lf.sort([\"c\", \"a\"], descending=True).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬─────┐\n",
      " |      │ a    ┆ b   ┆ c   │\n",
      " |      │ ---  ┆ --- ┆ --- │\n",
      " |      │ i64  ┆ f64 ┆ str │\n",
      " |      ╞══════╪═════╪═════╡\n",
      " |      │ 2    ┆ 5.0 ┆ c   │\n",
      " |      │ null ┆ 4.0 ┆ b   │\n",
      " |      │ 1    ┆ 6.0 ┆ a   │\n",
      " |      └──────┴─────┴─────┘\n",
      " |      \n",
      " |      Or use positional arguments to sort by multiple columns in the same way.\n",
      " |      \n",
      " |      >>> lf.sort(\"c\", \"a\", descending=[False, True]).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬─────┐\n",
      " |      │ a    ┆ b   ┆ c   │\n",
      " |      │ ---  ┆ --- ┆ --- │\n",
      " |      │ i64  ┆ f64 ┆ str │\n",
      " |      ╞══════╪═════╪═════╡\n",
      " |      │ 1    ┆ 6.0 ┆ a   │\n",
      " |      │ null ┆ 4.0 ┆ b   │\n",
      " |      │ 2    ┆ 5.0 ┆ c   │\n",
      " |      └──────┴─────┴─────┘\n",
      " |  \n",
      " |  std(self, ddof: 'int' = 1) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their standard deviation value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof\n",
      " |          “Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |          By default ddof is 1.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.std().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌──────────┬─────┐\n",
      " |      │ a        ┆ b   │\n",
      " |      │ ---      ┆ --- │\n",
      " |      │ f64      ┆ f64 │\n",
      " |      ╞══════════╪═════╡\n",
      " |      │ 1.290994 ┆ 0.5 │\n",
      " |      └──────────┴─────┘\n",
      " |      >>> lf.std(ddof=0).collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌──────────┬──────────┐\n",
      " |      │ a        ┆ b        │\n",
      " |      │ ---      ┆ ---      │\n",
      " |      │ f64      ┆ f64      │\n",
      " |      ╞══════════╪══════════╡\n",
      " |      │ 1.118034 ┆ 0.433013 │\n",
      " |      └──────────┴──────────┘\n",
      " |  \n",
      " |  sum(self) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their sum value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.sum().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 10  ┆ 5   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  tail(self, n: 'int' = 5) -> 'Self'\n",
      " |      Get the last `n` rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Number of rows to return.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...         \"b\": [7, 8, 9, 10, 11, 12],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.tail().collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 2   ┆ 8   │\n",
      " |      │ 3   ┆ 9   │\n",
      " |      │ 4   ┆ 10  │\n",
      " |      │ 5   ┆ 11  │\n",
      " |      │ 6   ┆ 12  │\n",
      " |      └─────┴─────┘\n",
      " |      >>> lf.tail(2).collect()\n",
      " |      shape: (2, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 5   ┆ 11  │\n",
      " |      │ 6   ┆ 12  │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  take_every(self, n: 'int', offset: 'int' = 0) -> 'Self'\n",
      " |      Take every nth row in the LazyFrame and return as a new LazyFrame.\n",
      " |      \n",
      " |      .. deprecated:: 0.19.0\n",
      " |          This method has been renamed to :meth:`gather_every`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n\n",
      " |          Gather every *n*-th row.\n",
      " |      offset\n",
      " |          Starting index.\n",
      " |  \n",
      " |  top_k(self, k: 'int', *, by: 'IntoExpr | Iterable[IntoExpr]', descending: 'bool | Sequence[bool]' = False, nulls_last: 'bool' = False, maintain_order: 'bool' = False) -> 'Self'\n",
      " |      Return the `k` largest elements.\n",
      " |      \n",
      " |      If `descending=True` the smallest elements will be given.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      k\n",
      " |          Number of rows to return.\n",
      " |      by\n",
      " |          Column(s) included in sort order. Accepts expression input.\n",
      " |          Strings are parsed as column names.\n",
      " |      descending\n",
      " |          Return the `k` smallest. Top-k by multiple columns can be specified\n",
      " |          per column by passing a sequence of booleans.\n",
      " |      nulls_last\n",
      " |          Place null values last.\n",
      " |      maintain_order\n",
      " |          Whether the order should be maintained if elements are equal.\n",
      " |          Note that if `true` streaming is not possible and performance might\n",
      " |          be worse since this requires a stable search.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      bottom_k\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n",
      " |      ...         \"b\": [2, 1, 1, 3, 2, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Get the rows which contain the 4 largest values in column b.\n",
      " |      \n",
      " |      >>> lf.top_k(4, by=\"b\").collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ b   ┆ 3   │\n",
      " |      │ a   ┆ 2   │\n",
      " |      │ b   ┆ 2   │\n",
      " |      │ b   ┆ 1   │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Get the rows which contain the 4 largest values when sorting on column b and a.\n",
      " |      \n",
      " |      >>> lf.top_k(4, by=[\"b\", \"a\"]).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ a   ┆ b   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ str ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ b   ┆ 3   │\n",
      " |      │ b   ┆ 2   │\n",
      " |      │ a   ┆ 2   │\n",
      " |      │ c   ┆ 1   │\n",
      " |      └─────┴─────┘\n",
      " |  \n",
      " |  unique(self, subset: 'ColumnNameOrSelector | Collection[ColumnNameOrSelector] | None' = None, *, keep: 'UniqueKeepStrategy' = 'any', maintain_order: 'bool' = False) -> 'Self'\n",
      " |      Drop duplicate rows from this DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset\n",
      " |          Column name(s) or selector(s), to consider when identifying\n",
      " |          duplicate rows. If set to `None` (default), use all columns.\n",
      " |      keep : {'first', 'last', 'any', 'none'}\n",
      " |          Which of the duplicate rows to keep.\n",
      " |      \n",
      " |          * 'any': Does not give any guarantee of which row is kept.\n",
      " |                   This allows more optimizations.\n",
      " |          * 'none': Don't keep duplicate rows.\n",
      " |          * 'first': Keep first unique row.\n",
      " |          * 'last': Keep last unique row.\n",
      " |      maintain_order\n",
      " |          Keep the same order as the original DataFrame. This is more expensive to\n",
      " |          compute.\n",
      " |          Settings this to `True` blocks the possibility\n",
      " |          to run on the streaming engine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyFrame\n",
      " |          LazyFrame with unique rows.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      This method will fail if there is a column of type `List` in the DataFrame or\n",
      " |      subset.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3, 1],\n",
      " |      ...         \"bar\": [\"a\", \"a\", \"a\", \"a\"],\n",
      " |      ...         \"ham\": [\"b\", \"b\", \"b\", \"b\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.unique(maintain_order=True).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ str ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ a   ┆ b   │\n",
      " |      │ 2   ┆ a   ┆ b   │\n",
      " |      │ 3   ┆ a   ┆ b   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      >>> lf.unique(subset=[\"bar\", \"ham\"], maintain_order=True).collect()\n",
      " |      shape: (1, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ str ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 1   ┆ a   ┆ b   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |      >>> lf.unique(keep=\"last\", maintain_order=True).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌─────┬─────┬─────┐\n",
      " |      │ foo ┆ bar ┆ ham │\n",
      " |      │ --- ┆ --- ┆ --- │\n",
      " |      │ i64 ┆ str ┆ str │\n",
      " |      ╞═════╪═════╪═════╡\n",
      " |      │ 2   ┆ a   ┆ b   │\n",
      " |      │ 3   ┆ a   ┆ b   │\n",
      " |      │ 1   ┆ a   ┆ b   │\n",
      " |      └─────┴─────┴─────┘\n",
      " |  \n",
      " |  unnest(self, columns: 'ColumnNameOrSelector | Collection[ColumnNameOrSelector]', *more_columns: 'ColumnNameOrSelector') -> 'Self'\n",
      " |      Decompose struct columns into separate columns for each of their fields.\n",
      " |      \n",
      " |      The new columns will be inserted into the DataFrame at the location of the\n",
      " |      struct column.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns\n",
      " |          Name of the struct column(s) that should be unnested.\n",
      " |      *more_columns\n",
      " |          Additional columns to unnest, specified as positional arguments.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"before\": [\"foo\", \"bar\"],\n",
      " |      ...         \"t_a\": [1, 2],\n",
      " |      ...         \"t_b\": [\"a\", \"b\"],\n",
      " |      ...         \"t_c\": [True, None],\n",
      " |      ...         \"t_d\": [[1, 2], [3]],\n",
      " |      ...         \"after\": [\"baz\", \"womp\"],\n",
      " |      ...     }\n",
      " |      ... ).select(\"before\", pl.struct(pl.col(\"^t_.$\")).alias(\"t_struct\"), \"after\")\n",
      " |      >>> df.collect()\n",
      " |      shape: (2, 3)\n",
      " |      ┌────────┬─────────────────────┬───────┐\n",
      " |      │ before ┆ t_struct            ┆ after │\n",
      " |      │ ---    ┆ ---                 ┆ ---   │\n",
      " |      │ str    ┆ struct[4]           ┆ str   │\n",
      " |      ╞════════╪═════════════════════╪═══════╡\n",
      " |      │ foo    ┆ {1,\"a\",true,[1, 2]} ┆ baz   │\n",
      " |      │ bar    ┆ {2,\"b\",null,[3]}    ┆ womp  │\n",
      " |      └────────┴─────────────────────┴───────┘\n",
      " |      >>> df.unnest(\"t_struct\").collect()\n",
      " |      shape: (2, 6)\n",
      " |      ┌────────┬─────┬─────┬──────┬───────────┬───────┐\n",
      " |      │ before ┆ t_a ┆ t_b ┆ t_c  ┆ t_d       ┆ after │\n",
      " |      │ ---    ┆ --- ┆ --- ┆ ---  ┆ ---       ┆ ---   │\n",
      " |      │ str    ┆ i64 ┆ str ┆ bool ┆ list[i64] ┆ str   │\n",
      " |      ╞════════╪═════╪═════╪══════╪═══════════╪═══════╡\n",
      " |      │ foo    ┆ 1   ┆ a   ┆ true ┆ [1, 2]    ┆ baz   │\n",
      " |      │ bar    ┆ 2   ┆ b   ┆ null ┆ [3]       ┆ womp  │\n",
      " |      └────────┴─────┴─────┴──────┴───────────┴───────┘\n",
      " |  \n",
      " |  update(self, other: 'LazyFrame', on: 'str | Sequence[str] | None' = None, how: \"Literal['left', 'inner', 'outer']\" = 'left', *, left_on: 'str | Sequence[str] | None' = None, right_on: 'str | Sequence[str] | None' = None, include_nulls: 'bool' = False) -> 'Self'\n",
      " |      Update the values in this `LazyFrame` with the non-null values in `other`.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          This functionality is considered **unstable**. It may be changed\n",
      " |          at any point without it being considered a breaking change.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other\n",
      " |          LazyFrame that will be used to update the values\n",
      " |      on\n",
      " |          Column names that will be joined on. If set to `None` (default),\n",
      " |          the implicit row index of each frame is used as a join key.\n",
      " |      how : {'left', 'inner', 'outer'}\n",
      " |          * 'left' will keep all rows from the left table; rows may be duplicated\n",
      " |            if multiple rows in the right frame match the left row's key.\n",
      " |          * 'inner' keeps only those rows where the key exists in both frames.\n",
      " |          * 'outer' will update existing rows where the key matches while also\n",
      " |            adding any new rows contained in the given frame.\n",
      " |      left_on\n",
      " |         Join column(s) of the left DataFrame.\n",
      " |      right_on\n",
      " |         Join column(s) of the right DataFrame.\n",
      " |      include_nulls\n",
      " |          If True, null values from the right DataFrame will be used to update the\n",
      " |          left DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is syntactic sugar for a left/inner join, with an optional coalesce when\n",
      " |      `include_nulls = False`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"A\": [1, 2, 3, 4],\n",
      " |      ...         \"B\": [400, 500, 600, 700],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ A   ┆ B   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ 400 │\n",
      " |      │ 2   ┆ 500 │\n",
      " |      │ 3   ┆ 600 │\n",
      " |      │ 4   ┆ 700 │\n",
      " |      └─────┴─────┘\n",
      " |      >>> new_lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"B\": [-66, None, -99],\n",
      " |      ...         \"C\": [5, 3, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Update `df` values with the non-null values in `new_df`, by row index:\n",
      " |      \n",
      " |      >>> lf.update(new_lf).collect()\n",
      " |      shape: (4, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ A   ┆ B   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ -66 │\n",
      " |      │ 2   ┆ 500 │\n",
      " |      │ 3   ┆ -99 │\n",
      " |      │ 4   ┆ 700 │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Update `df` values with the non-null values in `new_df`, by row index,\n",
      " |      but only keeping those rows that are common to both frames:\n",
      " |      \n",
      " |      >>> lf.update(new_lf, how=\"inner\").collect()\n",
      " |      shape: (3, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ A   ┆ B   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ -66 │\n",
      " |      │ 2   ┆ 500 │\n",
      " |      │ 3   ┆ -99 │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Update `df` values with the non-null values in `new_df`, using an outer join\n",
      " |      strategy that defines explicit join columns in each frame:\n",
      " |      \n",
      " |      >>> lf.update(new_lf, left_on=[\"A\"], right_on=[\"C\"], how=\"outer\").collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────┬─────┐\n",
      " |      │ A   ┆ B   │\n",
      " |      │ --- ┆ --- │\n",
      " |      │ i64 ┆ i64 │\n",
      " |      ╞═════╪═════╡\n",
      " |      │ 1   ┆ -99 │\n",
      " |      │ 2   ┆ 500 │\n",
      " |      │ 3   ┆ 600 │\n",
      " |      │ 4   ┆ 700 │\n",
      " |      │ 5   ┆ -66 │\n",
      " |      └─────┴─────┘\n",
      " |      \n",
      " |      Update `df` values including null values in `new_df`, using an outer join\n",
      " |      strategy that defines explicit join columns in each frame:\n",
      " |      \n",
      " |      >>> lf.update(\n",
      " |      ...     new_lf, left_on=\"A\", right_on=\"C\", how=\"outer\", include_nulls=True\n",
      " |      ... ).collect()\n",
      " |      shape: (5, 2)\n",
      " |      ┌─────┬──────┐\n",
      " |      │ A   ┆ B    │\n",
      " |      │ --- ┆ ---  │\n",
      " |      │ i64 ┆ i64  │\n",
      " |      ╞═════╪══════╡\n",
      " |      │ 1   ┆ -99  │\n",
      " |      │ 2   ┆ 500  │\n",
      " |      │ 3   ┆ null │\n",
      " |      │ 4   ┆ 700  │\n",
      " |      │ 5   ┆ -66  │\n",
      " |      └─────┴──────┘\n",
      " |  \n",
      " |  var(self, ddof: 'int' = 1) -> 'Self'\n",
      " |      Aggregate the columns in the LazyFrame to their variance value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof\n",
      " |          “Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |          By default ddof is 1.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [1, 2, 1, 1],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.var().collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌──────────┬──────┐\n",
      " |      │ a        ┆ b    │\n",
      " |      │ ---      ┆ ---  │\n",
      " |      │ f64      ┆ f64  │\n",
      " |      ╞══════════╪══════╡\n",
      " |      │ 1.666667 ┆ 0.25 │\n",
      " |      └──────────┴──────┘\n",
      " |      >>> lf.var(ddof=0).collect()\n",
      " |      shape: (1, 2)\n",
      " |      ┌──────┬────────┐\n",
      " |      │ a    ┆ b      │\n",
      " |      │ ---  ┆ ---    │\n",
      " |      │ f64  ┆ f64    │\n",
      " |      ╞══════╪════════╡\n",
      " |      │ 1.25 ┆ 0.1875 │\n",
      " |      └──────┴────────┘\n",
      " |  \n",
      " |  with_columns(self, *exprs: 'IntoExpr | Iterable[IntoExpr]', **named_exprs: 'IntoExpr') -> 'Self'\n",
      " |      Add columns to this LazyFrame.\n",
      " |      \n",
      " |      Added columns will replace existing columns with the same name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *exprs\n",
      " |          Column(s) to add, specified as positional arguments.\n",
      " |          Accepts expression input. Strings are parsed as column names, other\n",
      " |          non-expression inputs are parsed as literals.\n",
      " |      **named_exprs\n",
      " |          Additional columns to add, specified as keyword arguments.\n",
      " |          The columns will be renamed to the keyword used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyFrame\n",
      " |          A new LazyFrame with the columns added.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Creating a new LazyFrame using this method does not create a new copy of\n",
      " |      existing data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Pass an expression to add it as a new column.\n",
      " |      \n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 2, 3, 4],\n",
      " |      ...         \"b\": [0.5, 4, 10, 13],\n",
      " |      ...         \"c\": [True, True, False, True],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.with_columns((pl.col(\"a\") ** 2).alias(\"a^2\")).collect()\n",
      " |      shape: (4, 4)\n",
      " |      ┌─────┬──────┬───────┬──────┐\n",
      " |      │ a   ┆ b    ┆ c     ┆ a^2  │\n",
      " |      │ --- ┆ ---  ┆ ---   ┆ ---  │\n",
      " |      │ i64 ┆ f64  ┆ bool  ┆ f64  │\n",
      " |      ╞═════╪══════╪═══════╪══════╡\n",
      " |      │ 1   ┆ 0.5  ┆ true  ┆ 1.0  │\n",
      " |      │ 2   ┆ 4.0  ┆ true  ┆ 4.0  │\n",
      " |      │ 3   ┆ 10.0 ┆ false ┆ 9.0  │\n",
      " |      │ 4   ┆ 13.0 ┆ true  ┆ 16.0 │\n",
      " |      └─────┴──────┴───────┴──────┘\n",
      " |      \n",
      " |      Added columns will replace existing columns with the same name.\n",
      " |      \n",
      " |      >>> lf.with_columns(pl.col(\"a\").cast(pl.Float64)).collect()\n",
      " |      shape: (4, 3)\n",
      " |      ┌─────┬──────┬───────┐\n",
      " |      │ a   ┆ b    ┆ c     │\n",
      " |      │ --- ┆ ---  ┆ ---   │\n",
      " |      │ f64 ┆ f64  ┆ bool  │\n",
      " |      ╞═════╪══════╪═══════╡\n",
      " |      │ 1.0 ┆ 0.5  ┆ true  │\n",
      " |      │ 2.0 ┆ 4.0  ┆ true  │\n",
      " |      │ 3.0 ┆ 10.0 ┆ false │\n",
      " |      │ 4.0 ┆ 13.0 ┆ true  │\n",
      " |      └─────┴──────┴───────┘\n",
      " |      \n",
      " |      Multiple columns can be added by passing a list of expressions.\n",
      " |      \n",
      " |      >>> lf.with_columns(\n",
      " |      ...     [\n",
      " |      ...         (pl.col(\"a\") ** 2).alias(\"a^2\"),\n",
      " |      ...         (pl.col(\"b\") / 2).alias(\"b/2\"),\n",
      " |      ...         (pl.col(\"c\").not_()).alias(\"not c\"),\n",
      " |      ...     ]\n",
      " |      ... ).collect()\n",
      " |      shape: (4, 6)\n",
      " |      ┌─────┬──────┬───────┬──────┬──────┬───────┐\n",
      " |      │ a   ┆ b    ┆ c     ┆ a^2  ┆ b/2  ┆ not c │\n",
      " |      │ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---  ┆ ---   │\n",
      " |      │ i64 ┆ f64  ┆ bool  ┆ f64  ┆ f64  ┆ bool  │\n",
      " |      ╞═════╪══════╪═══════╪══════╪══════╪═══════╡\n",
      " |      │ 1   ┆ 0.5  ┆ true  ┆ 1.0  ┆ 0.25 ┆ false │\n",
      " |      │ 2   ┆ 4.0  ┆ true  ┆ 4.0  ┆ 2.0  ┆ false │\n",
      " |      │ 3   ┆ 10.0 ┆ false ┆ 9.0  ┆ 5.0  ┆ true  │\n",
      " |      │ 4   ┆ 13.0 ┆ true  ┆ 16.0 ┆ 6.5  ┆ false │\n",
      " |      └─────┴──────┴───────┴──────┴──────┴───────┘\n",
      " |      \n",
      " |      Multiple columns also can be added using positional arguments instead of a list.\n",
      " |      \n",
      " |      >>> lf.with_columns(\n",
      " |      ...     (pl.col(\"a\") ** 2).alias(\"a^2\"),\n",
      " |      ...     (pl.col(\"b\") / 2).alias(\"b/2\"),\n",
      " |      ...     (pl.col(\"c\").not_()).alias(\"not c\"),\n",
      " |      ... ).collect()\n",
      " |      shape: (4, 6)\n",
      " |      ┌─────┬──────┬───────┬──────┬──────┬───────┐\n",
      " |      │ a   ┆ b    ┆ c     ┆ a^2  ┆ b/2  ┆ not c │\n",
      " |      │ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---  ┆ ---   │\n",
      " |      │ i64 ┆ f64  ┆ bool  ┆ f64  ┆ f64  ┆ bool  │\n",
      " |      ╞═════╪══════╪═══════╪══════╪══════╪═══════╡\n",
      " |      │ 1   ┆ 0.5  ┆ true  ┆ 1.0  ┆ 0.25 ┆ false │\n",
      " |      │ 2   ┆ 4.0  ┆ true  ┆ 4.0  ┆ 2.0  ┆ false │\n",
      " |      │ 3   ┆ 10.0 ┆ false ┆ 9.0  ┆ 5.0  ┆ true  │\n",
      " |      │ 4   ┆ 13.0 ┆ true  ┆ 16.0 ┆ 6.5  ┆ false │\n",
      " |      └─────┴──────┴───────┴──────┴──────┴───────┘\n",
      " |      \n",
      " |      Use keyword arguments to easily name your expression inputs.\n",
      " |      \n",
      " |      >>> lf.with_columns(\n",
      " |      ...     ab=pl.col(\"a\") * pl.col(\"b\"),\n",
      " |      ...     not_c=pl.col(\"c\").not_(),\n",
      " |      ... ).collect()\n",
      " |      shape: (4, 5)\n",
      " |      ┌─────┬──────┬───────┬──────┬───────┐\n",
      " |      │ a   ┆ b    ┆ c     ┆ ab   ┆ not_c │\n",
      " |      │ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---   │\n",
      " |      │ i64 ┆ f64  ┆ bool  ┆ f64  ┆ bool  │\n",
      " |      ╞═════╪══════╪═══════╪══════╪═══════╡\n",
      " |      │ 1   ┆ 0.5  ┆ true  ┆ 0.5  ┆ false │\n",
      " |      │ 2   ┆ 4.0  ┆ true  ┆ 8.0  ┆ false │\n",
      " |      │ 3   ┆ 10.0 ┆ false ┆ 30.0 ┆ true  │\n",
      " |      │ 4   ┆ 13.0 ┆ true  ┆ 52.0 ┆ false │\n",
      " |      └─────┴──────┴───────┴──────┴───────┘\n",
      " |      \n",
      " |      Expressions with multiple outputs can be automatically instantiated as Structs\n",
      " |      by enabling the setting `Config.set_auto_structify(True)`:\n",
      " |      \n",
      " |      >>> with pl.Config(auto_structify=True):\n",
      " |      ...     lf.drop(\"c\").with_columns(\n",
      " |      ...         diffs=pl.col([\"a\", \"b\"]).diff().name.suffix(\"_diff\"),\n",
      " |      ...     ).collect()\n",
      " |      shape: (4, 3)\n",
      " |      ┌─────┬──────┬─────────────┐\n",
      " |      │ a   ┆ b    ┆ diffs       │\n",
      " |      │ --- ┆ ---  ┆ ---         │\n",
      " |      │ i64 ┆ f64  ┆ struct[2]   │\n",
      " |      ╞═════╪══════╪═════════════╡\n",
      " |      │ 1   ┆ 0.5  ┆ {null,null} │\n",
      " |      │ 2   ┆ 4.0  ┆ {1,3.5}     │\n",
      " |      │ 3   ┆ 10.0 ┆ {1,6.0}     │\n",
      " |      │ 4   ┆ 13.0 ┆ {1,3.0}     │\n",
      " |      └─────┴──────┴─────────────┘\n",
      " |  \n",
      " |  with_columns_seq(self, *exprs: 'IntoExpr | Iterable[IntoExpr]', **named_exprs: 'IntoExpr') -> 'Self'\n",
      " |      Add columns to this LazyFrame.\n",
      " |      \n",
      " |      Added columns will replace existing columns with the same name.\n",
      " |      \n",
      " |      This will run all expression sequentially instead of in parallel.\n",
      " |      Use this when the work per expression is cheap.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *exprs\n",
      " |          Column(s) to add, specified as positional arguments.\n",
      " |          Accepts expression input. Strings are parsed as column names, other\n",
      " |          non-expression inputs are parsed as literals.\n",
      " |      **named_exprs\n",
      " |          Additional columns to add, specified as keyword arguments.\n",
      " |          The columns will be renamed to the keyword used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      LazyFrame\n",
      " |          A new LazyFrame with the columns added.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      with_columns\n",
      " |  \n",
      " |  with_context(self, other: 'Self | list[Self]') -> 'Self'\n",
      " |      Add an external context to the computation graph.\n",
      " |      \n",
      " |      This allows expressions to also access columns from DataFrames\n",
      " |      that are not part of this one.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other\n",
      " |          Lazy DataFrame to join with.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame({\"a\": [1, 2, 3], \"b\": [\"a\", \"c\", None]})\n",
      " |      >>> lf_other = pl.LazyFrame({\"c\": [\"foo\", \"ham\"]})\n",
      " |      >>> lf.with_context(lf_other).select(\n",
      " |      ...     pl.col(\"b\") + pl.col(\"c\").first()\n",
      " |      ... ).collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌──────┐\n",
      " |      │ b    │\n",
      " |      │ ---  │\n",
      " |      │ str  │\n",
      " |      ╞══════╡\n",
      " |      │ afoo │\n",
      " |      │ cfoo │\n",
      " |      │ null │\n",
      " |      └──────┘\n",
      " |      \n",
      " |      Fill nulls with the median from another DataFrame:\n",
      " |      \n",
      " |      >>> train_lf = pl.LazyFrame(\n",
      " |      ...     {\"feature_0\": [-1.0, 0, 1], \"feature_1\": [-1.0, 0, 1]}\n",
      " |      ... )\n",
      " |      >>> test_lf = pl.LazyFrame(\n",
      " |      ...     {\"feature_0\": [-1.0, None, 1], \"feature_1\": [-1.0, 0, 1]}\n",
      " |      ... )\n",
      " |      >>> test_lf.with_context(\n",
      " |      ...     train_lf.select(pl.all().name.suffix(\"_train\"))\n",
      " |      ... ).select(\n",
      " |      ...     pl.col(\"feature_0\").fill_null(pl.col(\"feature_0_train\").median())\n",
      " |      ... ).collect()\n",
      " |      shape: (3, 1)\n",
      " |      ┌───────────┐\n",
      " |      │ feature_0 │\n",
      " |      │ ---       │\n",
      " |      │ f64       │\n",
      " |      ╞═══════════╡\n",
      " |      │ -1.0      │\n",
      " |      │ 0.0       │\n",
      " |      │ 1.0       │\n",
      " |      └───────────┘\n",
      " |  \n",
      " |  with_row_count(self, name: 'str' = 'row_nr', offset: 'int' = 0) -> 'Self'\n",
      " |      Add a column at index 0 that counts the rows.\n",
      " |      \n",
      " |      .. deprecated::\n",
      " |          Use :meth:`with_row_index` instead.\n",
      " |          Note that the default column name has changed from 'row_nr' to 'index'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name\n",
      " |          Name of the column to add.\n",
      " |      offset\n",
      " |          Start the row count at this offset.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      This can have a negative effect on query performance.\n",
      " |      This may, for instance, block predicate pushdown optimization.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 3, 5],\n",
      " |      ...         \"b\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.with_row_count().collect()  # doctest: +SKIP\n",
      " |      shape: (3, 3)\n",
      " |      ┌────────┬─────┬─────┐\n",
      " |      │ row_nr ┆ a   ┆ b   │\n",
      " |      │ ---    ┆ --- ┆ --- │\n",
      " |      │ u32    ┆ i64 ┆ i64 │\n",
      " |      ╞════════╪═════╪═════╡\n",
      " |      │ 0      ┆ 1   ┆ 2   │\n",
      " |      │ 1      ┆ 3   ┆ 4   │\n",
      " |      │ 2      ┆ 5   ┆ 6   │\n",
      " |      └────────┴─────┴─────┘\n",
      " |  \n",
      " |  with_row_index(self, name: 'str' = 'index', offset: 'int' = 0) -> 'Self'\n",
      " |      Add a row index as the first column in the LazyFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name\n",
      " |          Name of the index column.\n",
      " |      offset\n",
      " |          Start the index at this offset. Cannot be negative.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Using this function can have a negative effect on query performance.\n",
      " |      This may, for instance, block predicate pushdown optimization.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The resulting column does not have any special properties. It is a regular\n",
      " |      column of type `UInt32` (or `UInt64` in `polars-u64-idx`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": [1, 3, 5],\n",
      " |      ...         \"b\": [2, 4, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.with_row_index().collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌───────┬─────┬─────┐\n",
      " |      │ index ┆ a   ┆ b   │\n",
      " |      │ ---   ┆ --- ┆ --- │\n",
      " |      │ u32   ┆ i64 ┆ i64 │\n",
      " |      ╞═══════╪═════╪═════╡\n",
      " |      │ 0     ┆ 1   ┆ 2   │\n",
      " |      │ 1     ┆ 3   ┆ 4   │\n",
      " |      │ 2     ┆ 5   ┆ 6   │\n",
      " |      └───────┴─────┴─────┘\n",
      " |      >>> lf.with_row_index(\"id\", offset=1000).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌──────┬─────┬─────┐\n",
      " |      │ id   ┆ a   ┆ b   │\n",
      " |      │ ---  ┆ --- ┆ --- │\n",
      " |      │ u32  ┆ i64 ┆ i64 │\n",
      " |      ╞══════╪═════╪═════╡\n",
      " |      │ 1000 ┆ 1   ┆ 2   │\n",
      " |      │ 1001 ┆ 3   ┆ 4   │\n",
      " |      │ 1002 ┆ 5   ┆ 6   │\n",
      " |      └──────┴─────┴─────┘\n",
      " |      \n",
      " |      An index column can also be created using the expressions :func:`int_range`\n",
      " |      and :func:`len`.\n",
      " |      \n",
      " |      >>> lf.select(\n",
      " |      ...     pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"index\"),\n",
      " |      ...     pl.all(),\n",
      " |      ... ).collect()\n",
      " |      shape: (3, 3)\n",
      " |      ┌───────┬─────┬─────┐\n",
      " |      │ index ┆ a   ┆ b   │\n",
      " |      │ ---   ┆ --- ┆ --- │\n",
      " |      │ u32   ┆ i64 ┆ i64 │\n",
      " |      ╞═══════╪═════╪═════╡\n",
      " |      │ 0     ┆ 1   ┆ 2   │\n",
      " |      │ 1     ┆ 3   ┆ 4   │\n",
      " |      │ 2     ┆ 5   ┆ 6   │\n",
      " |      └───────┴─────┴─────┘\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  deserialize(source: 'str | Path | IOBase') -> 'Self' from builtins.type\n",
      " |      Read a logical plan from a JSON file to construct a LazyFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      source\n",
      " |          Path to a file or a file-like object (by file-like object, we refer to\n",
      " |          objects that have a `read()` method, such as a file handler (e.g.\n",
      " |          via builtin `open` function) or `BytesIO`).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LazyFrame.serialize\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import io\n",
      " |      >>> lf = pl.LazyFrame({\"a\": [1, 2, 3]}).sum()\n",
      " |      >>> json = lf.serialize()\n",
      " |      >>> pl.LazyFrame.deserialize(io.StringIO(json)).collect()\n",
      " |      shape: (1, 1)\n",
      " |      ┌─────┐\n",
      " |      │ a   │\n",
      " |      │ --- │\n",
      " |      │ i64 │\n",
      " |      ╞═════╡\n",
      " |      │ 6   │\n",
      " |      └─────┘\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  columns\n",
      " |      Get column names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6, 7, 8],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... ).select(\"foo\", \"bar\")\n",
      " |      >>> lf.columns\n",
      " |      ['foo', 'bar']\n",
      " |  \n",
      " |  dtypes\n",
      " |      Get dtypes of columns in LazyFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      schema : Returns a {colname:dtype} mapping.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6.0, 7.0, 8.0],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.dtypes\n",
      " |      [Int64, Float64, String]\n",
      " |  \n",
      " |  schema\n",
      " |      Get a dict[column name, DataType].\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [6.0, 7.0, 8.0],\n",
      " |      ...         \"ham\": [\"a\", \"b\", \"c\"],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.schema\n",
      " |      OrderedDict({'foo': Int64, 'bar': Float64, 'ham': String})\n",
      " |  \n",
      " |  width\n",
      " |      Get the width of the LazyFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> lf = pl.LazyFrame(\n",
      " |      ...     {\n",
      " |      ...         \"foo\": [1, 2, 3],\n",
      " |      ...         \"bar\": [4, 5, 6],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> lf.width\n",
      " |      2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_accessors': 'ClassVar[set[str]]', '_ldf': 'PyLazy...\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pl.LazyFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "screenpro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
